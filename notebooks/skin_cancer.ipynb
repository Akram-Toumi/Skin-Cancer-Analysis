{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de097c5133cc440d8ec6e38dd9f86d8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e7667e7e14a4e91859e234735273604",
              "IPY_MODEL_6e97e265d21948779edfcc61f27e6d45",
              "IPY_MODEL_218c81986f35425c9b15b45293036446"
            ],
            "layout": "IPY_MODEL_738343b9ad154841af727254af1d6c02"
          }
        },
        "0e7667e7e14a4e91859e234735273604": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ba8402e65e433992c303604a5ce1ed",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_ee8d151e80894523842c47bfd8ba780c",
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "6e97e265d21948779edfcc61f27e6d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_599032d13bb148208abb7f40a953e8b6",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06cc66e09fbc4a0d89353ee40c8bbacb",
            "value": 5
          }
        },
        "218c81986f35425c9b15b45293036446": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae06d1ee06144dea6aae477efe6b407",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_386b3c327b95434992ed315f57bde150",
            "value": "‚Äá5/5‚Äá[01:44&lt;00:00,‚Äá18.22s/it]"
          }
        },
        "738343b9ad154841af727254af1d6c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06ba8402e65e433992c303604a5ce1ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee8d151e80894523842c47bfd8ba780c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "599032d13bb148208abb7f40a953e8b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cc66e09fbc4a0d89353ee40c8bbacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ae06d1ee06144dea6aae477efe6b407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "386b3c327b95434992ed315f57bde150": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4-K_x6Rbho1",
        "outputId": "63e7378f-c19b-4320-ab3f-09286015fdcd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All dependencies installed! Please restart the runtime now.\n",
            "Go to: Runtime ‚Üí Restart runtime\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CELL 1: INSTALL DEPENDENCIES\n",
        "# ============================================================================\n",
        "# Run this cell first and restart runtime after completion\n",
        "# Group 1 - Model Loading & Quantization\n",
        "!pip install -q bitsandbytes transformers accelerate peft pillow sentencepiece protobuf\n",
        "# Group 2 - RAG & Vector Database\n",
        "!pip install -q langchain langchain-community faiss-cpu sentence-transformers datasets pandas\n",
        "# Group 3 - Computer Vision\n",
        "!pip install -q opencv-python-headless imutils scikit-image webcolors scikit-learn\n",
        "# Group 4 - Segment Anything (SAM) for fallback segmentation\n",
        "!pip install -q segment-anything\n",
        "# Group 5 - User Interface\n",
        "!pip install -q gradio\n",
        "# Group 6 - Additional utilities\n",
        "!pip install -q beautifulsoup4 requests matplotlib\n",
        "print(\"‚úÖ All dependencies installed! Please restart the runtime now.\")\n",
        "print(\"Go to: Runtime ‚Üí Restart runtime\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 2: IMPORTS\n",
        "# ============================================================================\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "import traceback\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "# Computer Vision\n",
        "from skimage import morphology, measure\n",
        "from sklearn.cluster import KMeans\n",
        "import webcolors\n",
        "# HuggingFace & Models\n",
        "from transformers import (\n",
        "    AutoProcessor,\n",
        "    MllamaForConditionalGeneration,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from peft import PeftModel\n",
        "from huggingface_hub import login\n",
        "# RAG Components\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_core.documents import Document\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"‚úÖ All imports successful!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7dobb0kbs35",
        "outputId": "a23571f5-d64b-4ee4-e391-90f29ce0b4f6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ All imports successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 3: HUGGINGFACE AUTHENTICATION (SAFE)\n",
        "# ============================================================================\n",
        "from huggingface_hub import login\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "def authenticate_huggingface():\n",
        "    \"\"\"Authenticate with HuggingFace Hub securely\"\"\"\n",
        "    try:\n",
        "        # Try Colab secrets\n",
        "        from google.colab import userdata\n",
        "        hf_token = userdata.get('HF_TOKEN')\n",
        "        if hf_token:\n",
        "            print(\"‚úÖ Found HF_TOKEN in Colab secrets\")\n",
        "        else:\n",
        "            raise ValueError\n",
        "    except:\n",
        "        print(\"‚ö†Ô∏è HF_TOKEN not found in Colab secrets\")\n",
        "        hf_token = getpass.getpass(\"Enter your HuggingFace token (hidden): \")\n",
        "\n",
        "    try:\n",
        "        login(token=hf_token)\n",
        "        print(\"‚úÖ Successfully logged into HuggingFace Hub!\")\n",
        "        return True\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Login failed: {e}\")\n",
        "        return False\n",
        "\n",
        "authenticate_huggingface()\n"
      ],
      "metadata": {
        "id": "4oM_qQSXbzjj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b4efba-3b9f-4514-9efc-57f22ae84691"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ö†Ô∏è HF_TOKEN not found in Colab secrets\n",
            "Enter your HuggingFace token (hidden): ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ Successfully logged into HuggingFace Hub!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 4: BUILD ENHANCED RAG KNOWLEDGE BASE\n",
        "# ============================================================================\n",
        "# Define medical keywords for classification\n",
        "SKIN_KEYWORDS = [\n",
        "    'melanoma', 'skin cancer', 'basal cell carcinoma', 'squamous cell carcinoma',\n",
        "    'dermatology', 'dermoscopy', 'cutaneous', 'skin lesion', 'nevus', 'mole',\n",
        "    'pigment network', 'blue-white veil', 'globules', 'dots', 'vascular',\n",
        "    'atypical', 'dysplastic', 'malignant', 'benign', 'biopsy', 'excision',\n",
        "    'breslow', 'clark level', 'sentinel node', 'metastasis', 'prognosis'\n",
        "]\n",
        "CARDIO_KEYWORDS = [\n",
        "    'cardiovascular', 'cardiac', 'heart', 'myocardial', 'coronary',\n",
        "    'stroke', 'hypertension', 'infarction'\n",
        "]\n",
        "def classify_abstract(text: str) -> Optional[str]:\n",
        "    \"\"\"Classify abstract by medical domain\"\"\"\n",
        "    if not text:\n",
        "        return None\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    has_skin = any(\n",
        "        re.search(r'\\b' + re.escape(kw) + r'\\b', text_lower)\n",
        "        if ' ' not in kw\n",
        "        else kw in text_lower\n",
        "        for kw in SKIN_KEYWORDS\n",
        "    )\n",
        "    has_cardio = any(\n",
        "        re.search(r'\\b' + re.escape(kw) + r'\\b', text_lower)\n",
        "        for kw in CARDIO_KEYWORDS\n",
        "    )\n",
        "\n",
        "    if has_skin and has_cardio:\n",
        "        return 'both'\n",
        "    elif has_skin:\n",
        "        return 'skin_cancer'\n",
        "    elif has_cardio:\n",
        "        return 'cardio'\n",
        "    return None\n",
        "def build_enhanced_rag_system():\n",
        "    \"\"\"Build multi-source RAG system with weighted retrieval\"\"\"\n",
        "    print(\"üîÑ Building Enhanced RAG Knowledge Base...\")\n",
        "\n",
        "    all_documents = []\n",
        "\n",
        "    # Source 1: Medical Abstracts (PubMed)\n",
        "    print(\"  üìö Loading medical abstracts...\")\n",
        "    try:\n",
        "        dataset = load_dataset(\"TimSchopf/medical_abstracts\", trust_remote_code=True)\n",
        "        combined = concatenate_datasets([dataset['train'], dataset['test']])\n",
        "\n",
        "        for item in combined:\n",
        "            text = item.get('medical_abstract', '') or item.get('text', '')\n",
        "            if text:\n",
        "                category = classify_abstract(text)\n",
        "                if category in ['skin_cancer', 'both']:\n",
        "                    all_documents.append(Document(\n",
        "                        page_content=text,\n",
        "                        metadata={\n",
        "                            'source': 'pubmed',\n",
        "                            'weight': 1.0,\n",
        "                            'type': 'research'\n",
        "                        }\n",
        "                    ))\n",
        "        print(f\"    ‚úÖ Loaded {len(all_documents)} relevant abstracts\")\n",
        "    except Exception as e:\n",
        "        print(f\"    ‚ö†Ô∏è Error loading abstracts: {e}\")\n",
        "\n",
        "    # Source 2: Clinical Guidelines (embedded knowledge)\n",
        "    print(\"  üìã Adding clinical guidelines...\")\n",
        "    guidelines = [\n",
        "        {\n",
        "            \"content\": \"\"\"ABCDE Criteria for Melanoma Detection (AAD Guidelines):\n",
        "            A - Asymmetry: One half unlike the other half\n",
        "            B - Border: Irregular, scalloped or poorly defined border\n",
        "            C - Color: Varied from one area to another; shades of tan, brown, black, white, red, blue\n",
        "            D - Diameter: Melanomas are usually greater than 6mm when diagnosed, but can be smaller\n",
        "            E - Evolving: A mole or skin lesion that looks different from the rest or is changing in size, shape or color\n",
        "            Any lesion meeting 2+ criteria warrants dermatological evaluation.\"\"\",\n",
        "            \"weight\": 2.0\n",
        "        },\n",
        "        {\n",
        "            \"content\": \"\"\"Dermoscopic Structures in Melanoma (Consensus Guidelines):\n",
        "            - Blue-white veil: Blue-white structureless area, present in 35% of melanomas\n",
        "            - Atypical pigment network: Irregular, thickened lines with variable mesh sizes\n",
        "            - Irregular dots/globules: Black, brown or blue dots of variable size randomly distributed\n",
        "            - Irregular streaks: Radial projections at the periphery, asymmetrically distributed\n",
        "            - Regression structures: Blue-gray peppering, white scar-like areas\n",
        "            - Atypical vessels: Polymorphous vessels including dotted, linear irregular, and hairpin vessels\n",
        "            Presence of 3+ structures highly predictive of melanoma.\"\"\",\n",
        "            \"weight\": 2.0\n",
        "        },\n",
        "        {\n",
        "            \"content\": \"\"\"Breslow Thickness and Prognosis (AJCC Guidelines):\n",
        "            - In situ: Confined to epidermis, excellent prognosis\n",
        "            - ‚â§1.0mm: 5-year survival >95%\n",
        "            - 1.01-2.0mm: 5-year survival 80-90%\n",
        "            - 2.01-4.0mm: 5-year survival 65-75%\n",
        "            - >4.0mm: 5-year survival <50%\n",
        "            Sentinel lymph node biopsy recommended for lesions >0.8mm with ulceration or >1.0mm.\"\"\",\n",
        "            \"weight\": 2.0\n",
        "        },\n",
        "        {\n",
        "            \"content\": \"\"\"Benign vs Malignant Dermoscopic Patterns:\n",
        "            BENIGN patterns: Symmetric pigment network, regular globules at periphery,\n",
        "            homogeneous brown color, cobblestone pattern, comma vessels.\n",
        "            MALIGNANT patterns: Asymmetry in structure and color, atypical network,\n",
        "            blue-white veil, irregular dots/globules, regression, polymorphous vessels.\n",
        "            The 2-step algorithm: Step 1 - Determine if melanocytic. Step 2 - If melanocytic,\n",
        "            determine if benign or malignant using pattern analysis.\"\"\",\n",
        "            \"weight\": 2.0\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for guideline in guidelines:\n",
        "        all_documents.append(Document(\n",
        "            page_content=guideline[\"content\"],\n",
        "            metadata={\n",
        "                'source': 'clinical_guidelines',\n",
        "                'weight': guideline[\"weight\"],\n",
        "                'type': 'guideline'\n",
        "            }\n",
        "        ))\n",
        "    print(f\"    ‚úÖ Added {len(guidelines)} clinical guidelines\")\n",
        "\n",
        "    # Source 3: Reference Knowledge\n",
        "    print(\"  üìñ Adding reference knowledge...\")\n",
        "    reference_docs = [\n",
        "        {\n",
        "            \"content\": \"\"\"Pigment Network Analysis:\n",
        "            Typical network: Light brown, thin lines forming a regular grid, fading at periphery.\n",
        "            Common in benign nevi. Atypical network: Thick, irregular lines with variable mesh size,\n",
        "            abrupt termination at periphery. Concerning for melanoma. Broadened network: Uniformly\n",
        "            thick lines, seen in dysplastic nevi. Negative network: Serpiginous interconnecting\n",
        "            hypopigmented lines, highly specific for melanoma.\"\"\",\n",
        "            \"weight\": 1.5\n",
        "        },\n",
        "        {\n",
        "            \"content\": \"\"\"Vascular Patterns in Dermoscopy:\n",
        "            Comma vessels: Curved, comma-shaped, typical of dermatofibromas.\n",
        "            Dotted vessels: Small red dots, seen in melanoma and Spitz nevi.\n",
        "            Linear irregular: Irregular caliber and course, melanoma indicator.\n",
        "            Arborizing vessels: Tree-like branching, pathognomonic for BCC.\n",
        "            Hairpin vessels: Loop-shaped, common in seborrheic keratosis.\n",
        "            Polymorphous: Multiple vessel types, highly suggestive of melanoma.\"\"\",\n",
        "            \"weight\": 1.5\n",
        "        },\n",
        "        {\n",
        "            \"content\": \"\"\"Blue-White Veil Clinical Significance:\n",
        "            Definition: Irregular, confluent blue-gray pigmentation with overlying white ground-glass film.\n",
        "            Histopathology: Corresponds to melanin in dermis with orthokeratosis above.\n",
        "            Specificity: Over 90% specific for melanoma when present focally.\n",
        "            Differential: Can be seen in heavily pigmented blue nevi.\n",
        "            Clinical action: Presence warrants excision with histopathological examination.\"\"\",\n",
        "            \"weight\": 1.5\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    for ref in reference_docs:\n",
        "        all_documents.append(Document(\n",
        "            page_content=ref[\"content\"],\n",
        "            metadata={\n",
        "                'source': 'reference',\n",
        "                'weight': ref[\"weight\"],\n",
        "                'type': 'reference'\n",
        "            }\n",
        "        ))\n",
        "    print(f\"    ‚úÖ Added {len(reference_docs)} reference documents\")\n",
        "\n",
        "    # Text chunking\n",
        "    print(\"  ‚úÇÔ∏è Chunking documents...\")\n",
        "    text_splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=500,\n",
        "        chunk_overlap=100\n",
        "    )\n",
        "    chunks = text_splitter.split_documents(all_documents)\n",
        "    print(f\"    ‚úÖ Created {len(chunks)} chunks\")\n",
        "\n",
        "    # Create embeddings and vector store\n",
        "    print(\"  üßÆ Creating embeddings and FAISS index...\")\n",
        "    embeddings = HuggingFaceEmbeddings(\n",
        "        model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        "    )\n",
        "    vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "    print(f\"‚úÖ RAG system ready with {len(chunks)} searchable chunks!\")\n",
        "\n",
        "    return vectorstore, embeddings\n",
        "# Build the RAG system\n",
        "vectorstore, embeddings = build_enhanced_rag_system()"
      ],
      "metadata": {
        "id": "B1FGAgodb3if",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cadd0d11-347a-4922-d1e1-05bacdb2b50a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'TimSchopf/medical_abstracts' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n",
            "ERROR:datasets.load:`trust_remote_code` is not supported anymore.\n",
            "Please check that the Hugging Face dataset 'TimSchopf/medical_abstracts' isn't based on a loading script and remove `trust_remote_code`.\n",
            "If the dataset is based on a loading script, please ask the dataset author to remove it and convert it to a standard format like Parquet.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Building Enhanced RAG Knowledge Base...\n",
            "  üìö Loading medical abstracts...\n",
            "    ‚úÖ Loaded 3241 relevant abstracts\n",
            "  üìã Adding clinical guidelines...\n",
            "    ‚úÖ Added 4 clinical guidelines\n",
            "  üìñ Adding reference knowledge...\n",
            "    ‚úÖ Added 3 reference documents\n",
            "  ‚úÇÔ∏è Chunking documents...\n",
            "    ‚úÖ Created 10961 chunks\n",
            "  üßÆ Creating embeddings and FAISS index...\n",
            "‚úÖ RAG system ready with 10961 searchable chunks!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 5: WEIGHTED RETRIEVAL AND FACT VERIFICATION\n",
        "# ============================================================================\n",
        "def weighted_retrieval(vectorstore, query: str, k: int = 10) -> List[Tuple[Document, float]]:\n",
        "    \"\"\"Retrieve documents with authority-weighted ranking\"\"\"\n",
        "    # Get more results than needed\n",
        "    results = vectorstore.similarity_search_with_score(query, k=k*2)\n",
        "\n",
        "    scored_results = []\n",
        "    for doc, sim_score in results:\n",
        "        weight = doc.metadata.get('weight', 1.0)\n",
        "\n",
        "        # Lower score = better similarity, so divide by weight\n",
        "        final_score = sim_score / weight\n",
        "        scored_results.append((doc, final_score, sim_score))\n",
        "\n",
        "    # Sort by final score (lower is better)\n",
        "    scored_results.sort(key=lambda x: x[1])\n",
        "\n",
        "    # Return top k with original similarity scores\n",
        "    return [(doc, orig_score) for doc, _, orig_score in scored_results[:k]]\n",
        "def verify_claim_support(claim: str, doc_content: str) -> bool:\n",
        "    \"\"\"Check if document content supports a claim\"\"\"\n",
        "    claim_words = set(claim.lower().split())\n",
        "    doc_words = set(doc_content.lower().split())\n",
        "\n",
        "    # Simple overlap check\n",
        "    overlap = len(claim_words & doc_words) / len(claim_words) if claim_words else 0\n",
        "    return overlap > 0.3\n",
        "def verify_with_multiple_sources(claim: str, vectorstore, k: int = 5) -> Tuple[str, float]:\n",
        "    \"\"\"Verify claim across multiple sources\"\"\"\n",
        "    results = vectorstore.similarity_search(claim, k=k)\n",
        "\n",
        "    support_count = sum(\n",
        "        1 for doc in results\n",
        "        if verify_claim_support(claim, doc.page_content)\n",
        "    )\n",
        "\n",
        "    confidence = support_count / len(results) if results else 0\n",
        "\n",
        "    if confidence > 0.8:\n",
        "        return \"High confidence (supported by multiple sources)\", confidence\n",
        "    elif confidence > 0.5:\n",
        "        return \"Moderate confidence (some support)\", confidence\n",
        "    else:\n",
        "        return \"Low confidence (limited support)\", confidence\n",
        "print(\"‚úÖ Retrieval functions ready!\")"
      ],
      "metadata": {
        "id": "GqyxBXA1b6tY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b263cad2-494c-4f60-a72d-214ea2013149"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Retrieval functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 6: LOAD LLAMA 3.2 VISION MODEL\n",
        "# ============================================================================\n",
        "print(\"üîÑ Loading Llama 3.2 Vision Model (this takes 2-3 minutes)...\")\n",
        "# Quantization configuration for memory efficiency\n",
        "quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    llm_int8_skip_modules=[\"vision_model\"]\n",
        ")\n",
        "# Load base model\n",
        "model_id = \"meta-llama/Llama-3.2-11B-Vision-Instruct\"\n",
        "print(f\"  üì• Loading base model: {model_id}\")\n",
        "model = MllamaForConditionalGeneration.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=quant_config,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    trust_remote_code=True\n",
        ")\n",
        "# Load processor\n",
        "print(\"  üì• Loading processor...\")\n",
        "processor = AutoProcessor.from_pretrained(model_id)\n",
        "# Load DermatoLLama adapter\n",
        "print(\"  üì• Loading DermatoLLama adapter...\")\n",
        "try:\n",
        "    adapter_id = \"DermaVLM/DermatoLLama-50k\"\n",
        "    model = PeftModel.from_pretrained(model, adapter_id)\n",
        "    print(\"  ‚úÖ DermatoLLama adapter loaded!\")\n",
        "except Exception as e:\n",
        "    print(f\"  ‚ö†Ô∏è Could not load adapter: {e}\")\n",
        "    print(\"  Continuing with base model...\")\n",
        "model.eval()\n",
        "print(\"‚úÖ Vision model ready!\")\n",
        "print(f\"  Device: {next(model.parameters()).device}\")"
      ],
      "metadata": {
        "id": "P_tDRf2XcCj5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "de097c5133cc440d8ec6e38dd9f86d8e",
            "0e7667e7e14a4e91859e234735273604",
            "6e97e265d21948779edfcc61f27e6d45",
            "218c81986f35425c9b15b45293036446",
            "738343b9ad154841af727254af1d6c02",
            "06ba8402e65e433992c303604a5ce1ed",
            "ee8d151e80894523842c47bfd8ba780c",
            "599032d13bb148208abb7f40a953e8b6",
            "06cc66e09fbc4a0d89353ee40c8bbacb",
            "8ae06d1ee06144dea6aae477efe6b407",
            "386b3c327b95434992ed315f57bde150"
          ]
        },
        "outputId": "6c3af18c-c1df-4abc-a5dd-2d6e2896fbd9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`torch_dtype` is deprecated! Use `dtype` instead!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Loading Llama 3.2 Vision Model (this takes 2-3 minutes)...\n",
            "  üì• Loading base model: meta-llama/Llama-3.2-11B-Vision-Instruct\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de097c5133cc440d8ec6e38dd9f86d8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  üì• Loading processor...\n",
            "  üì• Loading DermatoLLama adapter...\n",
            "  ‚úÖ DermatoLLama adapter loaded!\n",
            "‚úÖ Vision model ready!\n",
            "  Device: cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 7: CALIBRATION SYSTEM\n",
        "# ============================================================================\n",
        "def detect_reference_object(img_rgb: np.ndarray) -> Tuple[float, float, str]:\n",
        "    \"\"\"\n",
        "    Detect calibration reference objects in the image.\n",
        "    Returns: (pixels_per_mm, confidence, method)\n",
        "    \"\"\"\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    h, w = gray.shape\n",
        "\n",
        "    # Try to detect ruler markings (evenly spaced lines)\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "    lines = cv2.HoughLinesP(edges, 1, np.pi/180, threshold=50,\n",
        "                            minLineLength=20, maxLineGap=5)\n",
        "\n",
        "    if lines is not None and len(lines) > 10:\n",
        "        # Look for vertical lines at regular intervals (ruler graduations)\n",
        "        vertical_lines = []\n",
        "        for line in lines:\n",
        "            x1, y1, x2, y2 = line[0]\n",
        "            if abs(x2 - x1) < 5:  # Nearly vertical\n",
        "                vertical_lines.append((x1 + x2) / 2)\n",
        "\n",
        "        if len(vertical_lines) > 5:\n",
        "            vertical_lines = sorted(vertical_lines)\n",
        "            gaps = np.diff(vertical_lines)\n",
        "\n",
        "            # Check for regular spacing\n",
        "            if len(gaps) > 3:\n",
        "                median_gap = np.median(gaps)\n",
        "                consistent = np.sum(np.abs(gaps - median_gap) < median_gap * 0.3)\n",
        "\n",
        "                if consistent / len(gaps) > 0.6:\n",
        "                    # Assume 1mm between ruler marks\n",
        "                    pixels_per_mm = median_gap\n",
        "                    return pixels_per_mm, 0.85, \"ruler_detected\"\n",
        "\n",
        "    # Try to detect circles (coins)\n",
        "    circles = cv2.HoughCircles(\n",
        "        gray, cv2.HOUGH_GRADIENT, dp=1, minDist=50,\n",
        "        param1=100, param2=50, minRadius=20, maxRadius=100\n",
        "    )\n",
        "\n",
        "    if circles is not None:\n",
        "        circles = np.uint16(np.around(circles))\n",
        "        for circle in circles[0, :]:\n",
        "            x, y, r = circle\n",
        "            # Check if circle is near edge (likely calibration object)\n",
        "            if x < w * 0.2 or x > w * 0.8 or y < h * 0.2 or y > h * 0.8:\n",
        "                # Assume US penny (19.05mm diameter)\n",
        "                diameter_pixels = r * 2\n",
        "                pixels_per_mm = diameter_pixels / 19.05\n",
        "                return pixels_per_mm, 0.70, \"coin_detected\"\n",
        "\n",
        "    # Default: estimate based on typical dermoscopy\n",
        "    # Most dermoscopes have ~10-15 pixels per mm at standard zoom\n",
        "    return 10.0, 0.3, \"estimated_dermoscopy_default\"\n",
        "def apply_calibration(measurements: Dict, pixels_per_mm: float) -> Dict:\n",
        "    \"\"\"Convert pixel measurements to real-world units\"\"\"\n",
        "    calibrated = measurements.copy()\n",
        "\n",
        "    if 'area_pixels' in measurements:\n",
        "        calibrated['area_mm2'] = measurements['area_pixels'] / (pixels_per_mm ** 2)\n",
        "    if 'perimeter_pixels' in measurements:\n",
        "        calibrated['perimeter_mm'] = measurements['perimeter_pixels'] / pixels_per_mm\n",
        "    if 'diameter_pixels' in measurements:\n",
        "        calibrated['diameter_mm'] = measurements['diameter_pixels'] / pixels_per_mm\n",
        "\n",
        "    calibrated['pixels_per_mm'] = pixels_per_mm\n",
        "    return calibrated\n",
        "print(\"‚úÖ Calibration system ready!\")"
      ],
      "metadata": {
        "id": "Ph9-ZeN5cFua",
        "outputId": "de9f5dec-78be-48be-f6c1-ba44fcb39df1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Calibration system ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 8: IMAGE PREPROCESSING\n",
        "# ============================================================================\n",
        "def load_and_preprocess_pil(pil_image: Image.Image, max_dim: int = 1024) -> np.ndarray:\n",
        "    \"\"\"Convert PIL image to OpenCV format and resize\"\"\"\n",
        "    img = np.array(pil_image)\n",
        "\n",
        "    # Handle grayscale\n",
        "    if len(img.shape) == 2:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    # Handle RGBA\n",
        "    elif img.shape[2] == 4:\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_RGBA2RGB)\n",
        "\n",
        "    # Resize if needed\n",
        "    h, w = img.shape[:2]\n",
        "    if max(h, w) > max_dim:\n",
        "        scale = max_dim / max(h, w)\n",
        "        new_w, new_h = int(w * scale), int(h * scale)\n",
        "        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return img\n",
        "def remove_hairs(img_rgb: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Remove hair artifacts from dermoscopic images using black-hat transform\"\"\"\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Black-hat transform to detect dark lines (hairs)\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (9, 9))\n",
        "    blackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n",
        "\n",
        "    # Threshold to create hair mask\n",
        "    _, hair_mask = cv2.threshold(blackhat, 10, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Dilate to ensure full coverage\n",
        "    hair_mask = cv2.dilate(hair_mask, kernel, iterations=1)\n",
        "\n",
        "    # Inpaint using Telea algorithm\n",
        "    result = cv2.inpaint(img_rgb, hair_mask, inpaintRadius=3, flags=cv2.INPAINT_TELEA)\n",
        "\n",
        "    return result\n",
        "print(\"‚úÖ Preprocessing functions ready!\")"
      ],
      "metadata": {
        "id": "Ex0lsu_5cIZg",
        "outputId": "ecb5eddd-de9d-4f9f-b817-55b48a77cfab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Preprocessing functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 9: LESION SEGMENTATION\n",
        "# ============================================================================\n",
        "def segment_lesion_kmeans(img_rgb: np.ndarray, k: int = 2,\n",
        "                          min_size: int = 500) -> Tuple[Optional[np.ndarray], float]:\n",
        "    \"\"\"\n",
        "    Segment lesion using K-means clustering.\n",
        "    Returns: (mask, quality_score) or (None, 0) if failed\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Convert to LAB color space\n",
        "        img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)\n",
        "        h, w = img_lab.shape[:2]\n",
        "\n",
        "        # Reshape for K-means\n",
        "        pixels = img_lab.reshape(-1, 3).astype(np.float32)\n",
        "\n",
        "        # Apply K-means\n",
        "        criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 100, 0.2)\n",
        "        _, labels, centers = cv2.kmeans(pixels, k, None, criteria, 10,\n",
        "                                         cv2.KMEANS_RANDOM_CENTERS)\n",
        "\n",
        "        # Find darkest cluster (likely lesion)\n",
        "        avg_lightness = [centers[i][0] for i in range(k)]\n",
        "        lesion_cluster = np.argmin(avg_lightness)\n",
        "\n",
        "        # Create mask\n",
        "        mask = (labels.reshape(h, w) == lesion_cluster).astype(np.uint8) * 255\n",
        "\n",
        "        # Post-processing\n",
        "        mask_bool = mask > 0\n",
        "        mask_cleaned = morphology.remove_small_objects(mask_bool, min_size=min_size)\n",
        "        mask_filled = morphology.remove_small_holes(mask_cleaned, area_threshold=min_size)\n",
        "        mask = (mask_filled.astype(np.uint8)) * 255\n",
        "\n",
        "        # Calculate quality score\n",
        "        lesion_ratio = np.sum(mask > 0) / (h * w)\n",
        "        quality_score = 1.0\n",
        "\n",
        "        # Penalize if lesion too small or too large\n",
        "        if lesion_ratio < 0.05 or lesion_ratio > 0.8:\n",
        "            quality_score *= 0.5\n",
        "\n",
        "        # Check connectivity\n",
        "        num_labels, _ = cv2.connectedComponents(mask)\n",
        "        if num_labels > 2:  # Multiple disconnected regions\n",
        "            quality_score *= 0.7\n",
        "\n",
        "        if quality_score < 0.4:\n",
        "            return None, quality_score\n",
        "\n",
        "        return mask, quality_score\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"K-means segmentation error: {e}\")\n",
        "        return None, 0.0\n",
        "def segment_lesion_simple_fallback(img_rgb: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"Simple fallback segmentation using Otsu thresholding\"\"\"\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply Gaussian blur\n",
        "    blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
        "\n",
        "    # Otsu thresholding\n",
        "    _, mask = cv2.threshold(blurred, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "\n",
        "    # Morphological operations\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    return mask\n",
        "def segment_lesion(img_rgb: np.ndarray, k: int = 2,\n",
        "                   min_size: int = 500) -> Tuple[np.ndarray, str]:\n",
        "    \"\"\"\n",
        "    Robust segmentation with fallback.\n",
        "    Returns: (mask, method_used)\n",
        "    \"\"\"\n",
        "    # Try K-means first\n",
        "    mask, quality = segment_lesion_kmeans(img_rgb, k, min_size)\n",
        "\n",
        "    if mask is not None and quality >= 0.4:\n",
        "        return mask, \"kmeans\"\n",
        "\n",
        "    # Fallback to simple thresholding\n",
        "    print(\"  ‚ö†Ô∏è K-means failed, using fallback segmentation\")\n",
        "    mask = segment_lesion_simple_fallback(img_rgb)\n",
        "    return mask, \"fallback_otsu\"\n",
        "print(\"‚úÖ Segmentation functions ready!\")"
      ],
      "metadata": {
        "id": "DfQnXDHPcLLc",
        "outputId": "7c55aba4-cd02-430c-e61b-a9c5afcd4a74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Segmentation functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 10: SHAPE FEATURE EXTRACTION\n",
        "# ============================================================================\n",
        "def compute_shape_features(mask: np.ndarray, pixels_per_mm: float = 10.0) -> Dict:\n",
        "    \"\"\"Extract geometric measurements from lesion mask\"\"\"\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if not contours:\n",
        "        return {\"error\": \"No contours found\"}\n",
        "\n",
        "    # Get largest contour\n",
        "    contour = max(contours, key=cv2.contourArea)\n",
        "\n",
        "    # Basic measurements\n",
        "    area_pixels = cv2.contourArea(contour)\n",
        "    perimeter_pixels = cv2.arcLength(contour, True)\n",
        "    x, y, w, h = cv2.boundingRect(contour)\n",
        "    diameter_pixels = max(w, h)\n",
        "\n",
        "    # Circularity (1.0 = perfect circle)\n",
        "    circularity = 4 * np.pi * area_pixels / (perimeter_pixels ** 2) if perimeter_pixels > 0 else 0\n",
        "\n",
        "    # Asymmetry calculation\n",
        "    asymmetry_score = calculate_asymmetry(mask, contour)\n",
        "\n",
        "    # Convert to mm\n",
        "    features = {\n",
        "        'area_pixels': area_pixels,\n",
        "        'area_mm2': area_pixels / (pixels_per_mm ** 2),\n",
        "        'perimeter_pixels': perimeter_pixels,\n",
        "        'perimeter_mm': perimeter_pixels / pixels_per_mm,\n",
        "        'diameter_pixels': diameter_pixels,\n",
        "        'diameter_mm': diameter_pixels / pixels_per_mm,\n",
        "        'circularity': circularity,\n",
        "        'asymmetry': asymmetry_score,\n",
        "        'bounding_box': (x, y, w, h),\n",
        "        'pixels_per_mm': pixels_per_mm\n",
        "    }\n",
        "\n",
        "    return features\n",
        "def calculate_asymmetry(mask: np.ndarray, contour: np.ndarray) -> float:\n",
        "    \"\"\"Calculate asymmetry score (0-100, higher = more asymmetric)\"\"\"\n",
        "    try:\n",
        "        # Get contour points\n",
        "        points = contour.reshape(-1, 2).astype(np.float32)\n",
        "\n",
        "        # Calculate centroid\n",
        "        M = cv2.moments(contour)\n",
        "        if M['m00'] == 0:\n",
        "            return 50.0\n",
        "        cx = int(M['m10'] / M['m00'])\n",
        "        cy = int(M['m01'] / M['m00'])\n",
        "\n",
        "        # Center the points\n",
        "        centered = points - np.array([cx, cy])\n",
        "\n",
        "        # Compute covariance matrix and principal axes\n",
        "        cov = np.cov(centered.T)\n",
        "        eigenvalues, eigenvectors = np.linalg.eig(cov)\n",
        "\n",
        "        # Get rotation angle\n",
        "        angle = np.arctan2(eigenvectors[1, 0], eigenvectors[0, 0])\n",
        "\n",
        "        # Rotate mask to align with principal axis\n",
        "        h, w = mask.shape\n",
        "        rotation_matrix = cv2.getRotationMatrix2D((cx, cy), np.degrees(angle), 1.0)\n",
        "        rotated_mask = cv2.warpAffine(mask, rotation_matrix, (w, h))\n",
        "\n",
        "        # Split mask in half and compare\n",
        "        left_half = rotated_mask[:, :cx]\n",
        "        right_half = rotated_mask[:, cx:]\n",
        "\n",
        "        # Flip right half\n",
        "        right_flipped = cv2.flip(right_half, 1)\n",
        "\n",
        "        # Resize to match\n",
        "        min_w = min(left_half.shape[1], right_flipped.shape[1])\n",
        "        left_half = left_half[:, :min_w]\n",
        "        right_flipped = right_flipped[:, :min_w]\n",
        "\n",
        "        # Calculate difference\n",
        "        diff = np.abs(left_half.astype(float) - right_flipped.astype(float))\n",
        "        total_pixels = np.sum(mask > 0)\n",
        "\n",
        "        if total_pixels == 0:\n",
        "            return 50.0\n",
        "\n",
        "        asymmetry = (np.sum(diff > 0) / total_pixels) * 100\n",
        "        return min(asymmetry, 100.0)\n",
        "\n",
        "    except Exception as e:\n",
        "        return 50.0\n",
        "print(\"‚úÖ Shape feature extraction ready!\")"
      ],
      "metadata": {
        "id": "ldEvtKeNcQ48",
        "outputId": "1d9d0367-d33e-4bb3-8695-65700024298b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Shape feature extraction ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 11: COLOR ANALYSIS\n",
        "# ============================================================================\n",
        "def classify_dermatological_color(rgb: Tuple[int, int, int]) -> str:\n",
        "    \"\"\"Map RGB to clinical terminology\"\"\"\n",
        "    r, g, b = rgb\n",
        "\n",
        "    if r > 200 and g > 180 and b > 180:\n",
        "        return \"white/depigmented\"\n",
        "    elif r > 150 and g < 100 and b < 100:\n",
        "        return \"red/erythematous\"\n",
        "    elif r > 180 and g > 120 and b > 120:\n",
        "        return \"pink\"\n",
        "    elif r < 60 and g < 60 and b < 60:\n",
        "        return \"black/very dark brown\"\n",
        "    elif b > r and b > g and b > 80:\n",
        "        return \"blue-gray (regression)\"\n",
        "    elif r > 100:\n",
        "        if g > 80:\n",
        "            if r > 180:\n",
        "                return \"light brown/tan\"\n",
        "            elif r > 120:\n",
        "                return \"medium brown\"\n",
        "            else:\n",
        "                return \"dark brown\"\n",
        "        else:\n",
        "            return \"dark brown\"\n",
        "    return \"brown\"\n",
        "def get_color_name(rgb: Tuple[int, int, int]) -> str:\n",
        "    \"\"\"Get nearest CSS3 color name - compatible with all webcolors versions\"\"\"\n",
        "    try:\n",
        "        return webcolors.rgb_to_name(rgb)\n",
        "    except (ValueError, AttributeError):\n",
        "        min_dist = float('inf')\n",
        "        closest = 'gray'\n",
        "        color_map = {\n",
        "            'black': (0, 0, 0), 'white': (255, 255, 255),\n",
        "            'gray': (128, 128, 128), 'brown': (165, 42, 42),\n",
        "            'tan': (210, 180, 140), 'sienna': (160, 82, 45),\n",
        "            'pink': (255, 192, 203), 'salmon': (250, 128, 114),\n",
        "            'maroon': (128, 0, 0), 'navy': (0, 0, 128),\n",
        "        }\n",
        "        for name, (r_c, g_c, b_c) in color_map.items():\n",
        "            dist = (r_c - rgb[0])**2 + (g_c - rgb[1])**2 + (b_c - rgb[2])**2\n",
        "            if dist < min_dist:\n",
        "                min_dist = dist\n",
        "                closest = name\n",
        "        return closest\n",
        "def analyze_colors(img_rgb: np.ndarray, mask: np.ndarray,\n",
        "                   n_colors: int = 4) -> Tuple[List[Dict], np.ndarray, np.ndarray]:\n",
        "    \"\"\"Analyze dominant colors in lesion\"\"\"\n",
        "    # Extract lesion pixels\n",
        "    lesion_pixels = img_rgb[mask > 0]\n",
        "\n",
        "    if len(lesion_pixels) < 100:\n",
        "        return [], None, None\n",
        "\n",
        "    # K-means clustering\n",
        "    kmeans = KMeans(n_clusters=n_colors, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(lesion_pixels)\n",
        "    centers = kmeans.cluster_centers_.astype(int)\n",
        "\n",
        "    # Count pixels per cluster\n",
        "    unique, counts = np.unique(labels, return_counts=True)\n",
        "    total = len(labels)\n",
        "\n",
        "    # Sort by frequency\n",
        "    sorted_indices = np.argsort(counts)[::-1]\n",
        "\n",
        "    colors = []\n",
        "    for idx in sorted_indices:\n",
        "        rgb = tuple(centers[idx])\n",
        "        colors.append({\n",
        "            'rgb': rgb,\n",
        "            'css_name': get_color_name(rgb),\n",
        "            'clinical_name': classify_dermatological_color(rgb),\n",
        "            'percentage': counts[idx] / total * 100,\n",
        "            'count': counts[idx]\n",
        "        })\n",
        "\n",
        "    return colors, centers, labels\n",
        "def analyze_color_distribution(img_rgb: np.ndarray, mask: np.ndarray,\n",
        "                               centers: np.ndarray, labels: np.ndarray) -> Dict:\n",
        "    \"\"\"Analyze spatial distribution of colors\"\"\"\n",
        "    # Get lesion pixel coordinates\n",
        "    y_coords, x_coords = np.where(mask > 0)\n",
        "\n",
        "    if len(y_coords) == 0:\n",
        "        return {}\n",
        "\n",
        "    # Find center\n",
        "    center_y = np.mean(y_coords)\n",
        "    center_x = np.mean(x_coords)\n",
        "\n",
        "    # Calculate distances from center\n",
        "    distances = np.sqrt((y_coords - center_y)**2 + (x_coords - center_x)**2)\n",
        "    max_dist = np.max(distances) if len(distances) > 0 else 1\n",
        "\n",
        "    distribution = {}\n",
        "    for i, center in enumerate(centers):\n",
        "        color_mask = labels == i\n",
        "        color_dists = distances[color_mask]\n",
        "\n",
        "        if len(color_dists) > 0:\n",
        "            central = np.sum(color_dists < max_dist * 0.5)\n",
        "            peripheral = np.sum(color_dists >= max_dist * 0.5)\n",
        "            total = len(color_dists)\n",
        "\n",
        "            if central > peripheral * 1.5:\n",
        "                location = \"predominantly central\"\n",
        "            elif peripheral > central * 1.5:\n",
        "                location = \"predominantly peripheral\"\n",
        "            else:\n",
        "                location = \"mixed distribution\"\n",
        "\n",
        "            distribution[i] = {\n",
        "                'central_pct': central / total * 100,\n",
        "                'peripheral_pct': peripheral / total * 100,\n",
        "                'location': location\n",
        "            }\n",
        "\n",
        "    return distribution\n",
        "print(\"‚úÖ Color analysis functions ready!\")"
      ],
      "metadata": {
        "id": "TOTczcm1cT4P",
        "outputId": "f6a53ea9-4038-471e-c112-f639336f4ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Color analysis functions ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 12: BORDER AND TEXTURE ANALYSIS\n",
        "# ============================================================================\n",
        "def assess_border_quality(mask: np.ndarray) -> Dict:\n",
        "    \"\"\"Evaluate border characteristics\"\"\"\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if not contours:\n",
        "        return {\"error\": \"No contours found\"}\n",
        "\n",
        "    contour = max(contours, key=cv2.contourArea)\n",
        "    perimeter = cv2.arcLength(contour, True)\n",
        "\n",
        "    # Douglas-Peucker approximation\n",
        "    epsilon = 0.02 * perimeter\n",
        "    approx = cv2.approxPolyDP(contour, epsilon, True)\n",
        "    num_corners = len(approx)\n",
        "\n",
        "    # Irregularity score\n",
        "    irregularity_score = (num_corners / perimeter) * 1000 if perimeter > 0 else 0\n",
        "\n",
        "    # Border definition\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
        "    dilated = cv2.dilate(mask, kernel, iterations=1)\n",
        "    eroded = cv2.erode(mask, kernel, iterations=1)\n",
        "    border_zone = dilated - eroded\n",
        "    border_width = np.sum(border_zone > 0) / perimeter if perimeter > 0 else 0\n",
        "\n",
        "    # Classifications\n",
        "    if border_width < 3:\n",
        "        definition = \"well-defined\"\n",
        "    elif border_width < 6:\n",
        "        definition = \"moderately defined\"\n",
        "    else:\n",
        "        definition = \"poorly-defined\"\n",
        "\n",
        "    if irregularity_score > 10:\n",
        "        regularity = \"highly irregular/notched\"\n",
        "    elif irregularity_score > 5:\n",
        "        regularity = \"moderately irregular\"\n",
        "    else:\n",
        "        regularity = \"regular\"\n",
        "\n",
        "    return {\n",
        "        'irregularity_score': irregularity_score,\n",
        "        'num_corners': num_corners,\n",
        "        'border_width': border_width,\n",
        "        'regularity': regularity,\n",
        "        'definition': definition\n",
        "    }\n",
        "def analyze_texture_patterns(img_rgb: np.ndarray, mask: np.ndarray) -> Dict:\n",
        "    \"\"\"Assess surface texture and pigmentation patterns\"\"\"\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "    lesion_pixels = gray[mask > 0]\n",
        "\n",
        "    if len(lesion_pixels) == 0:\n",
        "        return {\"error\": \"No lesion pixels\"}\n",
        "\n",
        "    # Texture variance\n",
        "    variance = np.var(lesion_pixels)\n",
        "\n",
        "    # Edge detection within lesion\n",
        "    edges = cv2.Canny(gray, 50, 150)\n",
        "    lesion_edges = edges[mask > 0]\n",
        "    edge_density = np.sum(lesion_edges > 0) / len(lesion_pixels)\n",
        "\n",
        "    # Pattern classification\n",
        "    if edge_density > 0.15:\n",
        "        pattern = \"reticular/network pattern visible\"\n",
        "    elif edge_density > 0.05:\n",
        "        pattern = \"irregular pigmentation pattern\"\n",
        "    else:\n",
        "        pattern = \"homogeneous pigmentation\"\n",
        "\n",
        "    # Surface classification\n",
        "    if variance > 1000:\n",
        "        surface = \"highly textured/varied\"\n",
        "    elif variance > 500:\n",
        "        surface = \"moderately textured\"\n",
        "    else:\n",
        "        surface = \"smooth/uniform\"\n",
        "\n",
        "    return {\n",
        "        'variance': variance,\n",
        "        'edge_density': edge_density,\n",
        "        'pattern': pattern,\n",
        "        'surface': surface\n",
        "    }\n",
        "print(\"‚úÖ Border and texture analysis ready!\")"
      ],
      "metadata": {
        "id": "CSkYi9RhcWAr",
        "outputId": "e3992dd5-c4dd-4237-efee-6bf1a77cd756",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Border and texture analysis ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 13: BLUE-WHITE VEIL DETECTION\n",
        "# ============================================================================\n",
        "def detect_blue_white_veil(img_rgb: np.ndarray, mask: np.ndarray) -> Dict:\n",
        "    \"\"\"Detect blue-white veil (melanoma indicator)\"\"\"\n",
        "    # Convert to HSV\n",
        "    img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)\n",
        "\n",
        "    # Blue-white color ranges\n",
        "    # Blue: H=100-130 (in OpenCV: 50-65), S=30-150, V=80-180\n",
        "    blue_lower = np.array([50, 30, 80])\n",
        "    blue_upper = np.array([130, 150, 180])\n",
        "    blue_mask = cv2.inRange(img_hsv, blue_lower, blue_upper)\n",
        "\n",
        "    # White: Low saturation, high value\n",
        "    white_lower = np.array([0, 0, 200])\n",
        "    white_upper = np.array([180, 30, 255])\n",
        "    white_mask = cv2.inRange(img_hsv, white_lower, white_upper)\n",
        "\n",
        "    # Combined blue-white\n",
        "    bw_mask = cv2.bitwise_or(blue_mask, white_mask)\n",
        "\n",
        "    # Intersection with lesion\n",
        "    bw_in_lesion = cv2.bitwise_and(bw_mask, mask)\n",
        "\n",
        "    # Calculate coverage\n",
        "    lesion_area = np.sum(mask > 0)\n",
        "    bw_area = np.sum(bw_in_lesion > 0)\n",
        "    coverage = (bw_area / lesion_area * 100) if lesion_area > 0 else 0\n",
        "\n",
        "    # Determine distribution\n",
        "    if coverage < 5:\n",
        "        distribution = \"none\"\n",
        "        present = False\n",
        "    else:\n",
        "        present = True\n",
        "        # Check if focal or diffuse\n",
        "        y_coords, x_coords = np.where(bw_in_lesion > 0)\n",
        "        if len(y_coords) > 0:\n",
        "            spread = np.std(y_coords) + np.std(x_coords)\n",
        "            lesion_y, lesion_x = np.where(mask > 0)\n",
        "            lesion_spread = np.std(lesion_y) + np.std(lesion_x)\n",
        "\n",
        "            if spread < lesion_spread * 0.5:\n",
        "                distribution = \"focal\"\n",
        "            else:\n",
        "                distribution = \"diffuse\"\n",
        "        else:\n",
        "            distribution = \"none\"\n",
        "\n",
        "    return {\n",
        "        'present': present,\n",
        "        'coverage_percentage': round(coverage, 1),\n",
        "        'distribution': distribution,\n",
        "        'clinical_significance': \"Blue-white veil is a melanoma-specific structure. \"\n",
        "                                 \"Present in ~35% of melanomas. Presence significantly \"\n",
        "                                 \"increases melanoma probability.\" if present else \"\"\n",
        "    }\n",
        "print(\"‚úÖ Blue-white veil detection ready!\")"
      ],
      "metadata": {
        "id": "E9qik-a5cZ1o",
        "outputId": "e350402a-402c-4c4d-e1ab-7d2a7b2b6d04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Blue-white veil detection ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 14: PIGMENT NETWORK DETECTION\n",
        "# ============================================================================\n",
        "def detect_pigment_network(img_rgb: np.ndarray, mask: np.ndarray) -> Dict:\n",
        "    \"\"\"Detect and classify pigment network\"\"\"\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Apply adaptive thresholding to detect lines\n",
        "    block_size = 15\n",
        "    adaptive_thresh = cv2.adaptiveThreshold(\n",
        "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV, block_size, 2\n",
        "    )\n",
        "\n",
        "    # Apply within lesion\n",
        "    network_mask = cv2.bitwise_and(adaptive_thresh, mask)\n",
        "\n",
        "    # Morphological operations to identify network lines\n",
        "    kernel_thin = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))\n",
        "    kernel_thick = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
        "\n",
        "    thin_lines = cv2.morphologyEx(network_mask, cv2.MORPH_OPEN, kernel_thin)\n",
        "\n",
        "    # Calculate network density\n",
        "    lesion_area = np.sum(mask > 0)\n",
        "    network_area = np.sum(thin_lines > 0)\n",
        "    network_density = (network_area / lesion_area) if lesion_area > 0 else 0\n",
        "\n",
        "    # Detect line thickness variation\n",
        "    contours, _ = cv2.findContours(thin_lines, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    if not contours:\n",
        "        return {\n",
        "            'present': False,\n",
        "            'type': 'absent',\n",
        "            'characteristics': {},\n",
        "            'clinical_significance': \"\"\n",
        "        }\n",
        "\n",
        "    # Analyze line characteristics\n",
        "    thicknesses = []\n",
        "    for contour in contours:\n",
        "        if cv2.contourArea(contour) > 10:\n",
        "            _, _, w, h = cv2.boundingRect(contour)\n",
        "            thicknesses.append(min(w, h))\n",
        "\n",
        "    if len(thicknesses) > 0:\n",
        "        thickness_mean = np.mean(thicknesses)\n",
        "        thickness_std = np.std(thicknesses)\n",
        "        thickness_variation = thickness_std / thickness_mean if thickness_mean > 0 else 0\n",
        "    else:\n",
        "        thickness_mean = 0\n",
        "        thickness_variation = 0\n",
        "\n",
        "    # Classify network type\n",
        "    if network_density < 0.05:\n",
        "        network_type = \"absent\"\n",
        "        present = False\n",
        "    elif thickness_variation > 0.5:\n",
        "        network_type = \"atypical_network\"\n",
        "        present = True\n",
        "    elif thickness_mean > 3:\n",
        "        network_type = \"broadened_network\"\n",
        "        present = True\n",
        "    else:\n",
        "        network_type = \"typical_network\"\n",
        "        present = True\n",
        "\n",
        "    significance = \"\"\n",
        "    if network_type == \"atypical_network\":\n",
        "        significance = \"Atypical network with irregular lines is concerning for melanoma.\"\n",
        "    elif network_type == \"broadened_network\":\n",
        "        significance = \"Broadened network may indicate dysplastic nevus.\"\n",
        "    elif network_type == \"typical_network\":\n",
        "        significance = \"Typical regular network is common in benign nevi.\"\n",
        "\n",
        "    return {\n",
        "        'present': present,\n",
        "        'type': network_type,\n",
        "        'characteristics': {\n",
        "            'density': round(network_density, 3),\n",
        "            'thickness_mean': round(thickness_mean, 1),\n",
        "            'thickness_variation': round(thickness_variation, 2)\n",
        "        },\n",
        "        'clinical_significance': significance\n",
        "    }\n",
        "print(\"‚úÖ Pigment network detection ready!\")"
      ],
      "metadata": {
        "id": "x2e0VIUKccl9",
        "outputId": "bdb33d72-8b47-496e-bb5b-f5264e2c5ac6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Pigment network detection ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 15: GLOBULES, DOTS & VASCULAR STRUCTURES\n",
        "# ============================================================================\n",
        "def detect_globules_and_dots(img_rgb: np.ndarray, mask: np.ndarray,\n",
        "                             pixels_per_mm: float = 10.0) -> Dict:\n",
        "    \"\"\"Detect globular and dot patterns\"\"\"\n",
        "    gray = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    # Blob detection with LoG\n",
        "    from skimage.feature import blob_log\n",
        "\n",
        "    # Normalize for blob detection\n",
        "    gray_norm = gray / 255.0\n",
        "\n",
        "    try:\n",
        "        blobs = blob_log(gray_norm, min_sigma=1, max_sigma=10,\n",
        "                         num_sigma=5, threshold=0.1)\n",
        "    except:\n",
        "        blobs = np.array([])\n",
        "\n",
        "    # Filter blobs within lesion\n",
        "    dots = []\n",
        "    globules = []\n",
        "\n",
        "    for blob in blobs:\n",
        "        y, x, sigma = blob\n",
        "        y, x = int(y), int(x)\n",
        "\n",
        "        if y < mask.shape[0] and x < mask.shape[1] and mask[y, x] > 0:\n",
        "            radius_pixels = sigma * np.sqrt(2)\n",
        "            radius_mm = radius_pixels / pixels_per_mm\n",
        "            diameter_mm = radius_mm * 2\n",
        "\n",
        "            # Get color at blob center\n",
        "            color = img_rgb[y, x]\n",
        "\n",
        "            blob_info = {\n",
        "                'x': x, 'y': y,\n",
        "                'diameter_mm': round(diameter_mm, 2),\n",
        "                'color': classify_dermatological_color(tuple(color))\n",
        "            }\n",
        "\n",
        "            if diameter_mm < 1:\n",
        "                dots.append(blob_info)\n",
        "            elif diameter_mm < 3:\n",
        "                globules.append(blob_info)\n",
        "\n",
        "    # Analyze distribution\n",
        "    def get_distribution(items, mask):\n",
        "        if not items:\n",
        "            return \"none\"\n",
        "        y_coords = [item['y'] for item in items]\n",
        "        x_coords = [item['x'] for item in items]\n",
        "\n",
        "        lesion_y, lesion_x = np.where(mask > 0)\n",
        "        center_y, center_x = np.mean(lesion_y), np.mean(lesion_x)\n",
        "\n",
        "        central_count = sum(1 for i in range(len(items))\n",
        "                           if np.sqrt((y_coords[i]-center_y)**2 +\n",
        "                                     (x_coords[i]-center_x)**2) <\n",
        "                           np.std(lesion_y))\n",
        "\n",
        "        if central_count > len(items) * 0.6:\n",
        "            return \"central\"\n",
        "        elif central_count < len(items) * 0.3:\n",
        "            return \"peripheral\"\n",
        "        else:\n",
        "            return \"scattered\"\n",
        "\n",
        "    dots_dist = get_distribution(dots, mask)\n",
        "    globules_dist = get_distribution(globules, mask)\n",
        "\n",
        "    # Count by color\n",
        "    blue_gray_dots = len([d for d in dots if 'blue' in d['color'].lower()])\n",
        "\n",
        "    return {\n",
        "        'dots_count': len(dots),\n",
        "        'globules_count': len(globules),\n",
        "        'blue_gray_dots': blue_gray_dots,\n",
        "        'dots_distribution': dots_dist,\n",
        "        'globules_distribution': globules_dist,\n",
        "        'clinical_significance': (\n",
        "            \"Irregular dots and blue-gray dots suggest melanocytic neoplasm.\"\n",
        "            if blue_gray_dots > 0 else\n",
        "            \"Regular globular pattern common in benign nevi.\" if len(globules) > 5 else \"\"\n",
        "        )\n",
        "    }\n",
        "def detect_vascular_structures(img_rgb: np.ndarray, mask: np.ndarray) -> Dict:\n",
        "    \"\"\"Identify vascular patterns\"\"\"\n",
        "    # Enhance red channel\n",
        "    red_channel = img_rgb[:, :, 0].astype(float)\n",
        "    green_channel = img_rgb[:, :, 1].astype(float)\n",
        "\n",
        "    # Red enhancement\n",
        "    vessel_enhanced = np.clip(red_channel - green_channel * 0.5, 0, 255).astype(np.uint8)\n",
        "\n",
        "    # Apply within lesion\n",
        "    vessel_enhanced = cv2.bitwise_and(vessel_enhanced, mask)\n",
        "\n",
        "    # Threshold for vessels\n",
        "    _, vessel_mask = cv2.threshold(vessel_enhanced, 50, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "    # Morphological thinning\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    vessel_mask = cv2.morphologyEx(vessel_mask, cv2.MORPH_OPEN, kernel)\n",
        "\n",
        "    # Calculate vessel density\n",
        "    lesion_area = np.sum(mask > 0)\n",
        "    vessel_area = np.sum(vessel_mask > 0)\n",
        "    vessel_density = (vessel_area / lesion_area) if lesion_area > 0 else 0\n",
        "\n",
        "    # Detect vessel patterns by shape analysis\n",
        "    contours, _ = cv2.findContours(vessel_mask, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "    vessel_types = {\n",
        "        'dotted': 0,\n",
        "        'linear': 0,\n",
        "        'curved': 0\n",
        "    }\n",
        "\n",
        "    for contour in contours:\n",
        "        area = cv2.contourArea(contour)\n",
        "        perimeter = cv2.arcLength(contour, True)\n",
        "\n",
        "        if perimeter == 0 or area < 5:\n",
        "            continue\n",
        "\n",
        "        circularity = 4 * np.pi * area / (perimeter ** 2)\n",
        "\n",
        "        if circularity > 0.7:\n",
        "            vessel_types['dotted'] += 1\n",
        "        elif circularity < 0.3:\n",
        "            vessel_types['linear'] += 1\n",
        "        else:\n",
        "            vessel_types['curved'] += 1\n",
        "\n",
        "    # Determine dominant pattern\n",
        "    total = sum(vessel_types.values())\n",
        "    if total == 0:\n",
        "        dominant = \"none\"\n",
        "        significance = \"\"\n",
        "    else:\n",
        "        dominant = max(vessel_types, key=vessel_types.get)\n",
        "\n",
        "        if vessel_types['dotted'] > 0 and vessel_types['linear'] > 0:\n",
        "            dominant = \"polymorphous\"\n",
        "            significance = \"Polymorphous vessels highly suggestive of melanoma.\"\n",
        "        elif dominant == 'dotted':\n",
        "            significance = \"Dotted vessels can be seen in melanoma and Spitz nevi.\"\n",
        "        elif dominant == 'linear':\n",
        "            significance = \"Linear irregular vessels concerning for malignancy.\"\n",
        "        else:\n",
        "            significance = \"\"\n",
        "\n",
        "    return {\n",
        "        'present': total > 0,\n",
        "        'density': round(vessel_density, 3),\n",
        "        'types': vessel_types,\n",
        "        'dominant_pattern': dominant,\n",
        "        'clinical_significance': significance\n",
        "    }\n",
        "print(\"‚úÖ Globules, dots, and vascular detection ready!\")"
      ],
      "metadata": {
        "id": "OwUkpNKccfkP",
        "outputId": "e767c97b-18a7-4f61-f5a2-77427b4445c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Globules, dots, and vascular detection ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 16: COMPREHENSIVE DERMOSCOPIC ANALYSIS\n",
        "# ============================================================================\n",
        "def comprehensive_dermoscopic_analysis(img_rgb: np.ndarray, mask: np.ndarray,\n",
        "                                       pixels_per_mm: float = 10.0) -> Dict:\n",
        "    \"\"\"Integrate all dermoscopic structure detection\"\"\"\n",
        "    results = {\n",
        "        'blue_white_veil': detect_blue_white_veil(img_rgb, mask),\n",
        "        'pigment_network': detect_pigment_network(img_rgb, mask),\n",
        "        'globules_dots': detect_globules_and_dots(img_rgb, mask, pixels_per_mm),\n",
        "        'vascular': detect_vascular_structures(img_rgb, mask)\n",
        "    }\n",
        "\n",
        "    # Count concerning features\n",
        "    concerning_count = 0\n",
        "    concerning_features = []\n",
        "\n",
        "    if results['blue_white_veil']['present']:\n",
        "        concerning_count += 1\n",
        "        concerning_features.append(\"Blue-white veil\")\n",
        "\n",
        "    if results['pigment_network']['type'] == 'atypical_network':\n",
        "        concerning_count += 1\n",
        "        concerning_features.append(\"Atypical pigment network\")\n",
        "\n",
        "    if results['globules_dots']['blue_gray_dots'] > 0:\n",
        "        concerning_count += 1\n",
        "        concerning_features.append(\"Blue-gray dots\")\n",
        "\n",
        "    if results['vascular']['dominant_pattern'] == 'polymorphous':\n",
        "        concerning_count += 1\n",
        "        concerning_features.append(\"Polymorphous vessels\")\n",
        "\n",
        "    results['summary'] = {\n",
        "        'concerning_structure_count': concerning_count,\n",
        "        'concerning_features': concerning_features,\n",
        "        'melanoma_probability': 'HIGH' if concerning_count >= 3 else\n",
        "                               'MODERATE' if concerning_count >= 2 else\n",
        "                               'LOW' if concerning_count <= 1 else 'MODERATE'\n",
        "    }\n",
        "\n",
        "    return results\n",
        "print(\"‚úÖ Comprehensive dermoscopic analysis ready!\")"
      ],
      "metadata": {
        "id": "OpSCe3-3ckB_",
        "outputId": "8f6533c7-ce8d-48e6-9f84-cd748f2243ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Comprehensive dermoscopic analysis ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 17: ABCDE RISK ASSESSMENT\n",
        "# ============================================================================\n",
        "def calculate_abcde_risk(colors: List[Dict], shape: Dict, border: Dict,\n",
        "                         dermoscopic: Dict, temporal_changes: Optional[Dict] = None) -> Dict:\n",
        "    \"\"\"Automated melanoma risk assessment using ABCDE criteria\"\"\"\n",
        "    risk_factors = []\n",
        "    scores = {}\n",
        "\n",
        "    # A - Asymmetry\n",
        "    asymmetry = shape.get('asymmetry', 0)\n",
        "    scores['A_asymmetry'] = asymmetry\n",
        "    if asymmetry > 30:\n",
        "        risk_factors.append(f\"‚ö†Ô∏è A: Significant asymmetry detected (score: {asymmetry:.1f})\")\n",
        "\n",
        "    # B - Border\n",
        "    irregularity = border.get('irregularity_score', 0)\n",
        "    circularity = shape.get('circularity', 1)\n",
        "    scores['B_irregularity'] = irregularity\n",
        "    scores['B_circularity'] = circularity\n",
        "\n",
        "    if irregularity > 8 or circularity < 0.3:\n",
        "        risk_factors.append(f\"‚ö†Ô∏è B: Irregular border (irregularity: {irregularity:.1f}, \"\n",
        "                           f\"circularity: {circularity:.2f})\")\n",
        "\n",
        "    # C - Color\n",
        "    num_colors = len([c for c in colors if c['percentage'] > 5])\n",
        "    has_black = any('black' in c['clinical_name'].lower() for c in colors)\n",
        "    has_blue_gray = any('blue' in c['clinical_name'].lower() for c in colors)\n",
        "\n",
        "    scores['C_num_colors'] = num_colors\n",
        "    scores['C_has_black'] = has_black\n",
        "    scores['C_has_blue_gray'] = has_blue_gray\n",
        "\n",
        "    if num_colors >= 4:\n",
        "        risk_factors.append(f\"‚ö†Ô∏è C: Multiple colors present ({num_colors} distinct tones)\")\n",
        "    if has_black:\n",
        "        risk_factors.append(\"‚ö†Ô∏è C: Black pigmentation present\")\n",
        "    if has_blue_gray:\n",
        "        risk_factors.append(\"‚ö†Ô∏è C: Blue-gray areas (possible regression)\")\n",
        "\n",
        "    # D - Diameter\n",
        "    diameter = shape.get('diameter_mm', 0)\n",
        "    scores['D_diameter'] = diameter\n",
        "    if diameter > 6:\n",
        "        risk_factors.append(f\"‚ö†Ô∏è D: Diameter > 6mm ({diameter:.1f}mm)\")\n",
        "\n",
        "    # E - Evolving\n",
        "    if temporal_changes:\n",
        "        size_change = temporal_changes.get('size_change_pct', 0)\n",
        "        scores['E_size_change'] = size_change\n",
        "\n",
        "        if size_change > 20:\n",
        "            risk_factors.append(f\"‚ö†Ô∏è E: Rapid growth detected ({size_change:.1f}% increase)\")\n",
        "        elif size_change > 10:\n",
        "            risk_factors.append(f\"‚ö†Ô∏è E: Moderate growth ({size_change:.1f}% increase)\")\n",
        "    else:\n",
        "        scores['E_evolving'] = \"Not assessed (no temporal data)\"\n",
        "\n",
        "    # Add dermoscopic structure risks\n",
        "    if dermoscopic['summary']['concerning_structure_count'] >= 2:\n",
        "        risk_factors.append(f\"‚ö†Ô∏è Dermoscopic: {dermoscopic['summary']['concerning_structure_count']} \"\n",
        "                           f\"concerning structures ({', '.join(dermoscopic['summary']['concerning_features'])})\")\n",
        "\n",
        "    # Overall risk level\n",
        "    if len(risk_factors) >= 4:\n",
        "        overall_risk = \"HIGH\"\n",
        "    elif len(risk_factors) >= 2:\n",
        "        overall_risk = \"MODERATE\"\n",
        "    else:\n",
        "        overall_risk = \"LOW\"\n",
        "\n",
        "    return {\n",
        "        'risk_factors': risk_factors,\n",
        "        'scores': scores,\n",
        "        'overall_risk': overall_risk,\n",
        "        'criteria_met': len(risk_factors)\n",
        "    }\n",
        "print(\"‚úÖ ABCDE risk assessment ready!\")"
      ],
      "metadata": {
        "id": "kf62yEs3cmiE",
        "outputId": "5f67e4e8-23bf-4407-b5d9-3d8dc53bd19e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ ABCDE risk assessment ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 18: TEMPORAL COMPARISON FOR \"E\" (EVOLVING)\n",
        "# ============================================================================\n",
        "def compare_temporal_images(current_img: np.ndarray, previous_img: np.ndarray,\n",
        "                           days_between: int, pixels_per_mm: float = 10.0) -> Dict:\n",
        "    \"\"\"Detect changes over time for Evolving criterion\"\"\"\n",
        "    try:\n",
        "        # Preprocess both images\n",
        "        current_clean = remove_hairs(current_img)\n",
        "        previous_clean = remove_hairs(previous_img)\n",
        "\n",
        "        # Segment both\n",
        "        current_mask, _ = segment_lesion(current_clean)\n",
        "        previous_mask, _ = segment_lesion(previous_clean)\n",
        "\n",
        "        # Calculate areas\n",
        "        current_area = np.sum(current_mask > 0) / (pixels_per_mm ** 2)\n",
        "        previous_area = np.sum(previous_mask > 0) / (pixels_per_mm ** 2)\n",
        "\n",
        "        # Size change\n",
        "        if previous_area > 0:\n",
        "            size_change_pct = (current_area - previous_area) / previous_area * 100\n",
        "        else:\n",
        "            size_change_pct = 0\n",
        "\n",
        "        # Growth rate (per month)\n",
        "        months = days_between / 30.0\n",
        "        growth_rate = size_change_pct / months if months > 0 else 0\n",
        "\n",
        "        # Shape changes (asymmetry)\n",
        "        current_shape = compute_shape_features(current_mask, pixels_per_mm)\n",
        "        previous_shape = compute_shape_features(previous_mask, pixels_per_mm)\n",
        "\n",
        "        asymmetry_change = current_shape.get('asymmetry', 0) - previous_shape.get('asymmetry', 0)\n",
        "\n",
        "        # Color changes\n",
        "        current_colors, _, _ = analyze_colors(current_clean, current_mask)\n",
        "        previous_colors, _, _ = analyze_colors(previous_clean, previous_mask)\n",
        "\n",
        "        current_color_names = set(c['clinical_name'] for c in current_colors)\n",
        "        previous_color_names = set(c['clinical_name'] for c in previous_colors)\n",
        "\n",
        "        new_colors = current_color_names - previous_color_names\n",
        "\n",
        "        # Urgency assessment\n",
        "        if size_change_pct > 20 or growth_rate > 30:\n",
        "            urgency = \"URGENT - Rapid growth detected\"\n",
        "        elif size_change_pct > 10 or len(new_colors) > 0:\n",
        "            urgency = \"CONCERNING - Moderate changes\"\n",
        "        else:\n",
        "            urgency = \"STABLE - Minimal changes\"\n",
        "\n",
        "        return {\n",
        "            'size_change_pct': round(size_change_pct, 1),\n",
        "            'growth_rate_per_month': round(growth_rate, 1),\n",
        "            'asymmetry_change': round(asymmetry_change, 1),\n",
        "            'new_colors': list(new_colors),\n",
        "            'current_area_mm2': round(current_area, 1),\n",
        "            'previous_area_mm2': round(previous_area, 1),\n",
        "            'days_between': days_between,\n",
        "            'urgency': urgency\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        return {'error': str(e)}\n",
        "print(\"‚úÖ Temporal comparison ready!\")"
      ],
      "metadata": {
        "id": "oBXGRVXccpe0",
        "outputId": "c4762195-c602-4d62-fa11-c0dcf491ee4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Temporal comparison ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 19: UNCERTAINTY QUANTIFICATION\n",
        "# ============================================================================\n",
        "def calculate_prediction_confidence(calibration_info: Dict,\n",
        "                                    segmentation_method: str,\n",
        "                                    rag_results: List,\n",
        "                                    image_quality: float = 0.8) -> Dict:\n",
        "    \"\"\"Calculate confidence scores for the analysis\"\"\"\n",
        "\n",
        "    # Calibration confidence\n",
        "    cal_confidence = calibration_info.get('confidence', 0.3)\n",
        "    cal_method = calibration_info.get('method', 'estimated')\n",
        "\n",
        "    # Segmentation confidence\n",
        "    if segmentation_method == 'kmeans':\n",
        "        seg_confidence = 0.85\n",
        "    elif segmentation_method == 'sam':\n",
        "        seg_confidence = 0.90\n",
        "    else:\n",
        "        seg_confidence = 0.60\n",
        "\n",
        "    # RAG confidence (based on source diversity)\n",
        "    if rag_results:\n",
        "        source_types = set(doc.metadata.get('type', '') for doc, _ in rag_results)\n",
        "        source_diversity = len(source_types) / 4  # Max 4 types\n",
        "        high_weight_sources = sum(1 for doc, _ in rag_results\n",
        "                                  if doc.metadata.get('weight', 0) >= 1.5)\n",
        "        rag_confidence = min(0.5 + source_diversity * 0.3 + high_weight_sources * 0.05, 1.0)\n",
        "    else:\n",
        "        rag_confidence = 0.3\n",
        "\n",
        "    # Overall confidence (weighted average)\n",
        "    overall = (\n",
        "        cal_confidence * 0.2 +\n",
        "        seg_confidence * 0.25 +\n",
        "        image_quality * 0.25 +\n",
        "        rag_confidence * 0.3\n",
        "    )\n",
        "\n",
        "    # Confidence level\n",
        "    if overall > 0.75:\n",
        "        level = \"HIGH\"\n",
        "    elif overall > 0.5:\n",
        "        level = \"MODERATE\"\n",
        "    else:\n",
        "        level = \"LOW\"\n",
        "\n",
        "    return {\n",
        "        'overall': round(overall, 2),\n",
        "        'level': level,\n",
        "        'breakdown': {\n",
        "            'calibration': round(cal_confidence, 2),\n",
        "            'segmentation': round(seg_confidence, 2),\n",
        "            'image_quality': round(image_quality, 2),\n",
        "            'literature_support': round(rag_confidence, 2)\n",
        "        },\n",
        "        'calibration_method': cal_method\n",
        "    }\n",
        "def generate_uncertainty_report(confidence: Dict) -> str:\n",
        "    \"\"\"Generate human-readable uncertainty report\"\"\"\n",
        "    report = f\"\"\"\n",
        "ANALYSIS CONFIDENCE ASSESSMENT\n",
        "{'='*50}\n",
        "Overall Confidence: {confidence['level']} ({confidence['overall']*100:.0f}%)\n",
        "Confidence Breakdown:\n",
        "‚Ä¢ Size Measurement: {confidence['breakdown']['calibration']*100:.0f}% ({confidence['calibration_method']})\n",
        "‚Ä¢ Segmentation: {confidence['breakdown']['segmentation']*100:.0f}%\n",
        "‚Ä¢ Image Quality: {confidence['breakdown']['image_quality']*100:.0f}%\n",
        "‚Ä¢ Literature Support: {confidence['breakdown']['literature_support']*100:.0f}%\n",
        "\"\"\"\n",
        "\n",
        "    # Add warnings for low confidence areas\n",
        "    warnings = []\n",
        "    if confidence['breakdown']['calibration'] < 0.5:\n",
        "        warnings.append(\"‚ö†Ô∏è Size measurements estimated - no calibration reference detected\")\n",
        "    if confidence['breakdown']['segmentation'] < 0.7:\n",
        "        warnings.append(\"‚ö†Ô∏è Segmentation quality may affect accuracy\")\n",
        "    if confidence['breakdown']['literature_support'] < 0.5:\n",
        "        warnings.append(\"‚ö†Ô∏è Limited literature support for this case\")\n",
        "\n",
        "    if warnings:\n",
        "        report += \"Uncertainty Factors:\\n\" + \"\\n\".join(warnings) + \"\\n\"\n",
        "\n",
        "    return report\n",
        "print(\"‚úÖ Uncertainty quantification ready!\")"
      ],
      "metadata": {
        "id": "n3drXWw3csP_",
        "outputId": "70986871-8bf7-4733-8696-a1385fe666ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Uncertainty quantification ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 20: ENHANCED DESCRIPTION GENERATION\n",
        "# ============================================================================\n",
        "def make_enhanced_description(colors: List[Dict], shape: Dict, texture: Dict,\n",
        "                              border: Dict, color_distribution: Dict,\n",
        "                              dermoscopic: Dict, calibration: Dict,\n",
        "                              abcde: Dict, temporal: Optional[Dict] = None,\n",
        "                              confidence: Optional[Dict] = None) -> str:\n",
        "    \"\"\"Generate comprehensive clinical report\"\"\"\n",
        "\n",
        "    lines = []\n",
        "    lines.append(\"DERMATOLOGICAL LESION ANALYSIS\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    # Calibration Status\n",
        "    lines.append(\"\\nüìè CALIBRATION STATUS:\")\n",
        "    cal_conf = calibration.get('confidence', 0.3)\n",
        "    cal_method = calibration.get('method', 'estimated')\n",
        "    if cal_conf > 0.7:\n",
        "        lines.append(f\"  ‚úÖ {cal_method.replace('_', ' ').title()} (Confidence: {cal_conf*100:.0f}%)\")\n",
        "    else:\n",
        "        lines.append(f\"  ‚ö†Ô∏è Estimated measurements - {cal_method} (Confidence: {cal_conf*100:.0f}%)\")\n",
        "\n",
        "    # Morphology\n",
        "    lines.append(\"\\nüìê MORPHOLOGY:\")\n",
        "    lines.append(f\"  ‚Ä¢ Size: {shape.get('diameter_mm', 0):.1f}mm diameter, \"\n",
        "                f\"{shape.get('area_mm2', 0):.1f}mm¬≤ area\")\n",
        "\n",
        "    asym = shape.get('asymmetry', 0)\n",
        "    if asym > 40:\n",
        "        asym_class = \"markedly asymmetric\"\n",
        "    elif asym > 25:\n",
        "        asym_class = \"moderately asymmetric\"\n",
        "    else:\n",
        "        asym_class = \"relatively symmetric\"\n",
        "    lines.append(f\"  ‚Ä¢ Shape: {asym_class} (score: {asym:.1f})\")\n",
        "    lines.append(f\"  ‚Ä¢ Circularity: {shape.get('circularity', 0):.2f} (1.0 = perfect circle)\")\n",
        "    lines.append(f\"  ‚Ä¢ Border: {border.get('regularity', 'unknown')}, {border.get('definition', 'unknown')}\")\n",
        "\n",
        "    # Color Analysis\n",
        "    lines.append(\"\\nüé® COLOR ANALYSIS:\")\n",
        "    significant_colors = [c for c in colors if c['percentage'] > 5]\n",
        "    lines.append(f\"  ‚Ä¢ Distinct color zones: {len(significant_colors)}\")\n",
        "    for c in significant_colors[:5]:\n",
        "        dist = color_distribution.get(colors.index(c), {}).get('location', 'unknown')\n",
        "        lines.append(f\"  ‚Ä¢ {c['clinical_name']}: {c['percentage']:.1f}% ({dist})\")\n",
        "\n",
        "    if len(significant_colors) >= 4:\n",
        "        lines.append(\"  ‚Ä¢ Pattern: VARIEGATED (multiple distinct colors)\")\n",
        "    elif len(significant_colors) >= 2:\n",
        "        lines.append(\"  ‚Ä¢ Pattern: Multi-colored\")\n",
        "    else:\n",
        "        lines.append(\"  ‚Ä¢ Pattern: Homogeneous\")\n",
        "\n",
        "    # Dermoscopic Structures\n",
        "    lines.append(\"\\nüî¨ DERMOSCOPIC STRUCTURES:\")\n",
        "    bwv = dermoscopic.get('blue_white_veil', {})\n",
        "    lines.append(f\"  ‚Ä¢ Blue-white veil: {'‚úÖ PRESENT' if bwv.get('present') else '‚ùå Absent'}\")\n",
        "    if bwv.get('present'):\n",
        "        lines.append(f\"    Coverage: {bwv.get('coverage_percentage', 0):.1f}%, \"\n",
        "                    f\"Distribution: {bwv.get('distribution', 'unknown')}\")\n",
        "\n",
        "    pn = dermoscopic.get('pigment_network', {})\n",
        "    lines.append(f\"  ‚Ä¢ Pigment network: {pn.get('type', 'unknown').replace('_', ' ').title()}\")\n",
        "\n",
        "    gd = dermoscopic.get('globules_dots', {})\n",
        "    lines.append(f\"  ‚Ä¢ Dots: {gd.get('dots_count', 0)}, Globules: {gd.get('globules_count', 0)}\")\n",
        "    if gd.get('blue_gray_dots', 0) > 0:\n",
        "        lines.append(f\"    ‚ö†Ô∏è Blue-gray dots present: {gd.get('blue_gray_dots', 0)}\")\n",
        "\n",
        "    vasc = dermoscopic.get('vascular', {})\n",
        "    lines.append(f\"  ‚Ä¢ Vascular pattern: {vasc.get('dominant_pattern', 'none')}\")\n",
        "\n",
        "    # Texture\n",
        "    lines.append(\"\\nüìä TEXTURE & SURFACE:\")\n",
        "    lines.append(f\"  ‚Ä¢ Pattern: {texture.get('pattern', 'unknown')}\")\n",
        "    lines.append(f\"  ‚Ä¢ Surface: {texture.get('surface', 'unknown')}\")\n",
        "    lines.append(f\"  ‚Ä¢ Complexity score: {texture.get('variance', 0):.1f}\")\n",
        "\n",
        "    # ABCDE Assessment\n",
        "    lines.append(\"\\n‚ö†Ô∏è ABCDE MELANOMA RISK ASSESSMENT:\")\n",
        "    if abcde.get('risk_factors'):\n",
        "        for rf in abcde['risk_factors']:\n",
        "            lines.append(f\"  {rf}\")\n",
        "        lines.append(f\"\\n  Overall Risk: {abcde.get('overall_risk', 'UNKNOWN')}\")\n",
        "    else:\n",
        "        lines.append(\"  ‚úÖ No major ABCDE risk factors detected\")\n",
        "\n",
        "    # Temporal Changes\n",
        "    if temporal and 'error' not in temporal:\n",
        "        lines.append(\"\\nüìà TEMPORAL EVOLUTION:\")\n",
        "        lines.append(f\"  ‚Ä¢ Size change: {temporal.get('size_change_pct', 0):+.1f}% \"\n",
        "                    f\"over {temporal.get('days_between', 0)} days\")\n",
        "        lines.append(f\"  ‚Ä¢ Growth rate: {temporal.get('growth_rate_per_month', 0):.1f}%/month\")\n",
        "        if temporal.get('new_colors'):\n",
        "            lines.append(f\"  ‚Ä¢ New colors: {', '.join(temporal.get('new_colors', []))}\")\n",
        "        lines.append(f\"  ‚Ä¢ Assessment: {temporal.get('urgency', 'Unknown')}\")\n",
        "\n",
        "    # Confidence\n",
        "    if confidence:\n",
        "        lines.append(f\"\\nüìä ANALYSIS CONFIDENCE: {confidence.get('level', 'Unknown')} \"\n",
        "                    f\"({confidence.get('overall', 0)*100:.0f}%)\")\n",
        "\n",
        "    # Summary\n",
        "    lines.append(\"\\n\" + \"=\" * 60)\n",
        "    lines.append(\"SUMMARY FOR CLINICAL CORRELATION:\")\n",
        "\n",
        "    summary_parts = []\n",
        "    summary_parts.append(f\"This {shape.get('diameter_mm', 0):.1f}mm lesion presents with \"\n",
        "                        f\"{len(significant_colors)} distinct color zones\")\n",
        "\n",
        "    if abcde.get('overall_risk') == 'HIGH':\n",
        "        summary_parts.append(\"Multiple concerning ABCDE criteria warrant urgent evaluation.\")\n",
        "    elif abcde.get('overall_risk') == 'MODERATE':\n",
        "        summary_parts.append(\"Some concerning features warrant dermatological evaluation.\")\n",
        "    else:\n",
        "        summary_parts.append(\"Features appear largely benign but clinical correlation recommended.\")\n",
        "\n",
        "    lines.append(\"  \" + \" \".join(summary_parts))\n",
        "\n",
        "    # Disclaimer\n",
        "    lines.append(\"\\n\" + \"=\" * 60)\n",
        "    lines.append(\"‚öïÔ∏è DISCLAIMER:\")\n",
        "    lines.append(\"  This is an automated analysis for research/educational purposes.\")\n",
        "    lines.append(\"  NOT a substitute for clinical evaluation by a qualified dermatologist.\")\n",
        "    lines.append(\"  All findings must be confirmed with histopathological examination.\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "print(\"‚úÖ Description generation ready!\")"
      ],
      "metadata": {
        "id": "V6bTMBf6cxZr",
        "outputId": "75cc6495-5ab8-43d0-d3c7-31927b98313d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Description generation ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 21: MAIN OPENCV ANALYSIS PIPELINE\n",
        "# ============================================================================\n",
        "def analyze_lesion_opencv(pil_image: Image.Image,\n",
        "                          previous_image: Optional[Image.Image] = None,\n",
        "                          days_between: int = 0) -> Tuple[str, np.ndarray, np.ndarray, np.ndarray, Dict]:\n",
        "    \"\"\"Complete OpenCV analysis pipeline\"\"\"\n",
        "    try:\n",
        "        # Step 1: Preprocess\n",
        "        img_rgb = load_and_preprocess_pil(pil_image)\n",
        "        original = img_rgb.copy()\n",
        "\n",
        "        # Step 2: Calibration\n",
        "        pixels_per_mm, cal_conf, cal_method = detect_reference_object(img_rgb)\n",
        "        calibration = {\n",
        "            'pixels_per_mm': pixels_per_mm,\n",
        "            'confidence': cal_conf,\n",
        "            'method': cal_method\n",
        "        }\n",
        "\n",
        "        # Step 3: Remove hair\n",
        "        cleaned = remove_hairs(img_rgb)\n",
        "\n",
        "        # Step 4: Segment lesion\n",
        "        mask, seg_method = segment_lesion(cleaned)\n",
        "\n",
        "        # Step 5: Shape features\n",
        "        shape = compute_shape_features(mask, pixels_per_mm)\n",
        "\n",
        "        # Step 6: Color analysis\n",
        "        colors, centers, labels = analyze_colors(cleaned, mask)\n",
        "\n",
        "        # Step 7: Color distribution\n",
        "        if centers is not None and labels is not None:\n",
        "            color_dist = analyze_color_distribution(cleaned, mask, centers, labels)\n",
        "        else:\n",
        "            color_dist = {}\n",
        "\n",
        "        # Step 8: Texture\n",
        "        texture = analyze_texture_patterns(cleaned, mask)\n",
        "\n",
        "        # Step 9: Border\n",
        "        border = assess_border_quality(mask)\n",
        "\n",
        "        # Step 10: Dermoscopic structures\n",
        "        dermoscopic = comprehensive_dermoscopic_analysis(cleaned, mask, pixels_per_mm)\n",
        "\n",
        "        # Step 11: Temporal comparison\n",
        "        temporal = None\n",
        "        if previous_image is not None and days_between > 0:\n",
        "            prev_rgb = load_and_preprocess_pil(previous_image)\n",
        "            temporal = compare_temporal_images(cleaned, prev_rgb, days_between, pixels_per_mm)\n",
        "\n",
        "        # Step 12: ABCDE risk\n",
        "        abcde = calculate_abcde_risk(colors, shape, border, dermoscopic, temporal)\n",
        "\n",
        "        # Step 13: Confidence\n",
        "        confidence = calculate_prediction_confidence(\n",
        "            calibration, seg_method, [], 0.8\n",
        "        )\n",
        "\n",
        "        # Step 14: Generate description\n",
        "        description = make_enhanced_description(\n",
        "            colors, shape, texture, border, color_dist,\n",
        "            dermoscopic, calibration, abcde, temporal, confidence\n",
        "        )\n",
        "\n",
        "        # Compile all data\n",
        "        all_data = {\n",
        "            'calibration': calibration,\n",
        "            'shape': shape,\n",
        "            'colors': colors,\n",
        "            'color_distribution': color_dist,\n",
        "            'texture': texture,\n",
        "            'border': border,\n",
        "            'dermoscopic': dermoscopic,\n",
        "            'abcde': abcde,\n",
        "            'temporal': temporal,\n",
        "            'confidence': confidence,\n",
        "            'segmentation_method': seg_method\n",
        "        }\n",
        "\n",
        "        return description, original, cleaned, mask, all_data\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"OpenCV Analysis Error:\\n{traceback.format_exc()}\"\n",
        "        return error_msg, None, None, None, {}\n",
        "print(\"‚úÖ Main OpenCV analysis pipeline ready!\")"
      ],
      "metadata": {
        "id": "hF_7u5KFc1Et",
        "outputId": "2eb54c52-9944-48cf-d15f-d7072f2f86eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Main OpenCV analysis pipeline ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 22: MAIN GRADIO ANALYSIS FUNCTION\n",
        "# ============================================================================\n",
        "def analyze_lesion_complete(image, previous_image, previous_date,\n",
        "                            use_opencv, manual_data,\n",
        "                            max_tokens, temperature, num_sources):\n",
        "    \"\"\"Main analysis orchestrator for Gradio interface\"\"\"\n",
        "    try:\n",
        "        # Input validation\n",
        "        if image is None:\n",
        "            return (\"‚ùå Please upload an image\", \"\", \"\", \"\", \"\")\n",
        "        # Convert to PIL RGB\n",
        "        if not isinstance(image, Image.Image):\n",
        "            image = Image.fromarray(image)\n",
        "        image = image.convert('RGB')\n",
        "        # Initialize outputs\n",
        "        opencv_output = \"\"\n",
        "        dermoscopic_output = \"\"\n",
        "        sources_output = \"\"\n",
        "        diagnosis_output = \"\"\n",
        "        confidence_output = \"\"\n",
        "        precomputed_data = None\n",
        "        analysis_mode = \"\"\n",
        "        all_analysis_data = {}\n",
        "        # Parse previous date\n",
        "        days_between = 0\n",
        "        prev_image_pil = None\n",
        "        if previous_image is not None and previous_date:\n",
        "            try:\n",
        "                prev_date = datetime.strptime(previous_date.strip(), \"%Y-%m-%d\")\n",
        "                days_between = (datetime.now() - prev_date).days\n",
        "                prev_image_pil = Image.fromarray(previous_image).convert('RGB')\n",
        "            except:\n",
        "                pass\n",
        "        # Feature extraction\n",
        "        if use_opencv:\n",
        "            print(\"üî¨ Running OpenCV feature extraction...\")\n",
        "            description, orig, cleaned, mask, all_analysis_data = analyze_lesion_opencv(\n",
        "                image, prev_image_pil, days_between\n",
        "            )\n",
        "            opencv_output = description\n",
        "            precomputed_data = description\n",
        "            analysis_mode = \"üî¨ OpenCV Feature Extraction\"\n",
        "            # Format dermoscopic output\n",
        "            if all_analysis_data and 'dermoscopic' in all_analysis_data:\n",
        "                derm = all_analysis_data['dermoscopic']\n",
        "                dermoscopic_output = format_dermoscopic_report(derm)\n",
        "            else:\n",
        "                dermoscopic_output = \"Dermoscopic analysis not available (OpenCV analysis may have encountered an issue)\"\n",
        "            # Confidence output\n",
        "            if all_analysis_data and 'confidence' in all_analysis_data:\n",
        "                confidence_output = generate_uncertainty_report(all_analysis_data['confidence'])\n",
        "            else:\n",
        "                confidence_output = \"Confidence data not available\"\n",
        "        elif manual_data and manual_data.strip():\n",
        "            precomputed_data = manual_data\n",
        "            analysis_mode = \"üìä Manual Pre-computed Data\"\n",
        "        else:\n",
        "            analysis_mode = \"üëÅÔ∏è Direct VLM Analysis\"\n",
        "        # RAG Retrieval\n",
        "        print(\"üìö Retrieving relevant medical literature...\")\n",
        "        query_terms = [\n",
        "            \"melanoma\", \"atypical nevus\", \"dysplastic nevus\", \"ABCDE criteria\",\n",
        "            \"dermoscopy patterns\", \"pigment network\", \"blue-white veil\",\n",
        "            \"skin cancer diagnosis\", \"benign nevus\", \"basal cell carcinoma\"\n",
        "        ]\n",
        "        query = \" \".join(query_terms)\n",
        "        rag_results = weighted_retrieval(vectorstore, query, k=num_sources)\n",
        "        # Format sources\n",
        "        sources_lines = [f\"**{analysis_mode}**\\n\"]\n",
        "        sources_lines.append(f\"**Found {len(rag_results)} relevant sources:**\\n\")\n",
        "        retrieved_context = \"\"\n",
        "        for i, (doc, score) in enumerate(rag_results, 1):\n",
        "            source_type = doc.metadata.get('type', 'research')\n",
        "            weight = doc.metadata.get('weight', 1.0)\n",
        "            sources_lines.append(f\"**[Source {i}]** ({source_type.title()}, Weight: {weight})\")\n",
        "            sources_lines.append(f\"Relevance Score: {score:.4f}\")\n",
        "            sources_lines.append(f\"{doc.page_content[:300]}...\")\n",
        "            sources_lines.append(\"-\" * 50)\n",
        "            retrieved_context += f\"\\n[Source {i}] ({source_type}):\\n{doc.page_content}\\n\"\n",
        "        sources_output = \"\\n\".join(sources_lines)\n",
        "        # Build VLM prompt\n",
        "        print(\"üß† Running VLM analysis...\")\n",
        "        analysis_prompt = build_vlm_prompt(precomputed_data, retrieved_context)\n",
        "        # VLM Inference\n",
        "        messages = [\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"image\"},\n",
        "                {\"type\": \"text\", \"text\": analysis_prompt}\n",
        "            ]}\n",
        "        ]\n",
        "        input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
        "        # Prepare inputs\n",
        "        inputs = processor(\n",
        "            image,\n",
        "            input_text,\n",
        "            add_special_tokens=False,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(model.device)\n",
        "        # Generate\n",
        "        with torch.no_grad():\n",
        "            output = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=int(max_tokens),\n",
        "                do_sample=True,\n",
        "                temperature=float(temperature)\n",
        "            )\n",
        "        # Decode\n",
        "        response = processor.decode(output[0], skip_special_tokens=True)\n",
        "        # Extract assistant response\n",
        "        if \"assistant\" in response.lower():\n",
        "            diagnosis_output = response.split(\"assistant\")[-1].strip()\n",
        "        else:\n",
        "            diagnosis_output = response\n",
        "        # Clean up response\n",
        "        if diagnosis_output.startswith(\":\"):\n",
        "            diagnosis_output = diagnosis_output[1:].strip()\n",
        "        # Save report\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"analysis_{timestamp}.txt\"\n",
        "        full_report = f\"\"\"\n",
        "SKIN LESION ANALYSIS REPORT\n",
        "{'='*60}\n",
        "Generated: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
        "Analysis Mode: {analysis_mode}\n",
        "{'='*60}\n",
        "{opencv_output if opencv_output else \"OpenCV analysis not used\"}\n",
        "{'='*60}\n",
        "EVIDENCE-BASED DIAGNOSIS:\n",
        "{'='*60}\n",
        "{diagnosis_output}\n",
        "{'='*60}\n",
        "SOURCES CONSULTED:\n",
        "{'='*60}\n",
        "{sources_output}\n",
        "{'='*60}\n",
        "DISCLAIMER: For research and educational purposes only.\n",
        "NOT a substitute for professional medical evaluation.\n",
        "{'='*60}\n",
        "\"\"\"\n",
        "        with open(filename, 'w') as f:\n",
        "            f.write(full_report)\n",
        "        print(f\"üíæ Report saved: {filename}\")\n",
        "        return (opencv_output, dermoscopic_output, sources_output,\n",
        "                diagnosis_output, confidence_output)\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Analysis Error:\\n{traceback.format_exc()}\"\n",
        "        return (error_msg, \"\", \"\", \"\", \"\")\n",
        "def format_dermoscopic_report(derm: Dict) -> str:\n",
        "    \"\"\"Format dermoscopic analysis for display\"\"\"\n",
        "    lines = [\"DERMOSCOPIC STRUCTURE ANALYSIS\", \"=\" * 50, \"\"]\n",
        "    # Blue-white veil\n",
        "    bwv = derm.get('blue_white_veil', {})\n",
        "    lines.append(\"BLUE-WHITE VEIL:\")\n",
        "    if bwv.get('present'):\n",
        "        lines.append(f\"  ‚úÖ PRESENT - Coverage: {bwv.get('coverage_percentage', 0):.1f}%\")\n",
        "        lines.append(f\"  Distribution: {bwv.get('distribution', 'unknown')}\")\n",
        "        lines.append(f\"  {bwv.get('clinical_significance', '')}\")\n",
        "    else:\n",
        "        lines.append(\"  ‚ùå Absent\")\n",
        "    # Pigment network\n",
        "    pn = derm.get('pigment_network', {})\n",
        "    lines.append(\"\\nPIGMENT NETWORK:\")\n",
        "    lines.append(f\"  Type: {pn.get('type', 'unknown').replace('_', ' ').title()}\")\n",
        "    if pn.get('characteristics'):\n",
        "        chars = pn['characteristics']\n",
        "        lines.append(f\"  Density: {chars.get('density', 0):.3f}\")\n",
        "        lines.append(f\"  Thickness variation: {chars.get('thickness_variation', 0):.2f}\")\n",
        "    if pn.get('clinical_significance'):\n",
        "        lines.append(f\"  {pn.get('clinical_significance', '')}\")\n",
        "    # Globules and dots\n",
        "    gd = derm.get('globules_dots', {})\n",
        "    lines.append(\"\\nGLOBULES AND DOTS:\")\n",
        "    lines.append(f\"  Dots detected: {gd.get('dots_count', 0)}\")\n",
        "    lines.append(f\"  Globules detected: {gd.get('globules_count', 0)}\")\n",
        "    if gd.get('blue_gray_dots', 0) > 0:\n",
        "        lines.append(f\"  ‚ö†Ô∏è Blue-gray dots: {gd.get('blue_gray_dots', 0)}\")\n",
        "    lines.append(f\"  Distribution: {gd.get('dots_distribution', 'unknown')}\")\n",
        "    # Vascular\n",
        "    vasc = derm.get('vascular', {})\n",
        "    lines.append(\"\\nVASCULAR STRUCTURES:\")\n",
        "    if vasc.get('present'):\n",
        "        lines.append(f\"  Pattern: {vasc.get('dominant_pattern', 'none')}\")\n",
        "        types = vasc.get('types', {})\n",
        "        lines.append(f\"  Types: Dotted={types.get('dotted', 0)}, \"\n",
        "                    f\"Linear={types.get('linear', 0)}, Curved={types.get('curved', 0)}\")\n",
        "        if vasc.get('clinical_significance'):\n",
        "            lines.append(f\"  {vasc.get('clinical_significance', '')}\")\n",
        "    else:\n",
        "        lines.append(\"  ‚ùå Not significant\")\n",
        "    # Summary\n",
        "    summary = derm.get('summary', {})\n",
        "    lines.append(\"\\n\" + \"=\" * 50)\n",
        "    lines.append(f\"CONCERNING STRUCTURES: {summary.get('concerning_structure_count', 0)}\")\n",
        "    if summary.get('concerning_features'):\n",
        "        lines.append(f\"Features: {', '.join(summary.get('concerning_features', []))}\")\n",
        "    lines.append(f\"MELANOMA PROBABILITY: {summary.get('melanoma_probability', 'Unknown')}\")\n",
        "    return \"\\n\".join(lines)\n",
        "def build_vlm_prompt(precomputed_data: Optional[str], retrieved_context: str) -> str:\n",
        "    \"\"\"Build the VLM analysis prompt\"\"\"\n",
        "    if precomputed_data:\n",
        "        prompt = f\"\"\"You are an expert dermatologist analyzing a skin lesion.\n",
        "QUANTITATIVE MEASUREMENTS FROM COMPUTER VISION:\n",
        "{precomputed_data}\n",
        "{'='*60}\n",
        "RELEVANT MEDICAL LITERATURE:\n",
        "{'='*60}\n",
        "{retrieved_context}\n",
        "{'='*60}\n",
        "EVIDENCE-BASED ANALYSIS INSTRUCTIONS:\n",
        "{'='*60}\n",
        "Based on the quantitative measurements AND medical literature, provide a structured diagnosis.\n",
        "**MANDATORY: Cite sources using [Source 1], [Source 2], etc.**\n",
        "Structure your response:\n",
        "1. DIFFERENTIAL DIAGNOSIS (Ranked by Likelihood):\n",
        "   - Provide 3-5 diagnoses with likelihood levels\n",
        "   - Reference specific measurements\n",
        "   - Cite literature for each\n",
        "2. CONCERNING FEATURES WITH EVIDENCE:\n",
        "   - List specific features from measurements\n",
        "   - Explain clinical significance with citations\n",
        "3. CLINICAL RECOMMENDATIONS:\n",
        "   - Urgency level (Immediate/Urgent/Routine)\n",
        "   - Specific next steps (biopsy type, excision, monitoring)\n",
        "   - Cite sources for recommendations\n",
        "4. PATIENT COMMUNICATION:\n",
        "   - Clear explanation of findings\n",
        "   - What to expect next\n",
        "Remember: Cite [Source X] for clinical claims.\"\"\"\n",
        "    else:\n",
        "        prompt = f\"\"\"You are an expert dermatologist. Analyze this skin lesion image.\n",
        "Evaluate:\n",
        "- Size, shape, symmetry\n",
        "- Border characteristics\n",
        "- Color zones and distribution\n",
        "- ABCDE criteria\n",
        "{'='*60}\n",
        "MEDICAL LITERATURE:\n",
        "{'='*60}\n",
        "{retrieved_context}\n",
        "Provide structured analysis:\n",
        "1. DIFFERENTIAL DIAGNOSIS (3-5 options with likelihood)\n",
        "2. CONCERNING FEATURES\n",
        "3. CLINICAL RECOMMENDATIONS\n",
        "4. PATIENT COMMUNICATION\n",
        "Cite sources as [Source X].\"\"\"\n",
        "    return prompt\n",
        "print(\"‚úÖ Main analysis function ready!\")"
      ],
      "metadata": {
        "id": "hl3Z9LfWc53e",
        "outputId": "db8b4efe-be3f-4ac6-b021-032f974a05cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Main analysis function ready!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# CELL 23: GRADIO INTERFACE\n",
        "# ============================================================================\n",
        "# Custom CSS\n",
        "custom_css = \"\"\"\n",
        ".gradio-container {\n",
        "    max-width: 1400px !important;\n",
        "    margin: auto;\n",
        "}\n",
        ".output-textbox textarea {\n",
        "    max-height: 500px;\n",
        "    overflow-y: auto !important;\n",
        "    font-family: 'Courier New', monospace;\n",
        "    font-size: 13px;\n",
        "}\n",
        "\"\"\"\n",
        "# Build interface\n",
        "with gr.Blocks(css=custom_css, theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "    gr.Markdown(\"\"\"\n",
        "    # üî¨ Complete Skin Cancer Analysis System\n",
        "    ### OpenCV + Vision-Language Model + RAG Evidence-Based Diagnosis\n",
        "\n",
        "    > ‚ö†Ô∏è **DISCLAIMER**: This tool is for **research and educational purposes only**.\n",
        "    > It is NOT FDA-approved and should NOT be used for clinical diagnosis.\n",
        "    > All findings must be confirmed by a qualified dermatologist.\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Row():\n",
        "        # Left Column - Inputs\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### üì§ Upload Images\")\n",
        "\n",
        "            image_input = gr.Image(\n",
        "                type=\"pil\",\n",
        "                label=\"Current Skin Lesion Image\",\n",
        "                height=300\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"üìÖ Previous Image (for Evolution Analysis)\", open=False):\n",
        "                previous_image = gr.Image(\n",
        "                    type=\"numpy\",\n",
        "                    label=\"Previous Image (optional)\"\n",
        "                )\n",
        "                previous_date = gr.Textbox(\n",
        "                    label=\"Previous Image Date (YYYY-MM-DD)\",\n",
        "                    placeholder=\"e.g., 2024-06-15\"\n",
        "                )\n",
        "\n",
        "            gr.Markdown(\"### üîß Analysis Options\")\n",
        "\n",
        "            use_opencv = gr.Checkbox(\n",
        "                value=True,\n",
        "                label=\"‚úÖ Use OpenCV Feature Extraction (Recommended)\"\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"üìä Manual Pre-computed Data\", open=False):\n",
        "                manual_data = gr.Textbox(\n",
        "                    label=\"Paste measurements here (optional)\",\n",
        "                    lines=5,\n",
        "                    placeholder=\"Use this if you have pre-computed measurements...\"\n",
        "                )\n",
        "\n",
        "            with gr.Accordion(\"‚öôÔ∏è Advanced Settings\", open=False):\n",
        "                max_tokens = gr.Slider(\n",
        "                    512, 2048, value=1024, step=128,\n",
        "                    label=\"Max Response Tokens\"\n",
        "                )\n",
        "                temperature = gr.Slider(\n",
        "                    0.1, 1.0, value=0.5, step=0.1,\n",
        "                    label=\"Temperature (lower = more focused)\"\n",
        "                )\n",
        "                num_sources = gr.Slider(\n",
        "                    1, 10, value=5, step=1,\n",
        "                    label=\"Number of Literature Sources\"\n",
        "                )\n",
        "\n",
        "            analyze_btn = gr.Button(\n",
        "                \"üî¨ Analyze Lesion\",\n",
        "                variant=\"primary\",\n",
        "                size=\"lg\"\n",
        "            )\n",
        "\n",
        "        # Right Column - Outputs\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### üìä Analysis Results\")\n",
        "\n",
        "            with gr.Tabs():\n",
        "                with gr.Tab(\"üìê OpenCV Features\"):\n",
        "                    opencv_output = gr.Textbox(\n",
        "                        label=\"Quantitative Measurements\",\n",
        "                        lines=20,\n",
        "                        max_lines=30,\n",
        "                        show_copy_button=True\n",
        "                    )\n",
        "\n",
        "                with gr.Tab(\"üî¨ Dermoscopic Structures\"):\n",
        "                    dermoscopic_output = gr.Textbox(\n",
        "                        label=\"Structure Analysis\",\n",
        "                        lines=18,\n",
        "                        max_lines=25,\n",
        "                        show_copy_button=True\n",
        "                    )\n",
        "\n",
        "                with gr.Tab(\"üìö Literature Sources\"):\n",
        "                    sources_output = gr.Textbox(\n",
        "                        label=\"Retrieved Medical Literature\",\n",
        "                        lines=15,\n",
        "                        max_lines=25,\n",
        "                        show_copy_button=True\n",
        "                    )\n",
        "\n",
        "                with gr.Tab(\"ü©∫ Evidence-Based Diagnosis\"):\n",
        "                    diagnosis_output = gr.Textbox(\n",
        "                        label=\"VLM Diagnosis with Citations\",\n",
        "                        lines=18,\n",
        "                        max_lines=30,\n",
        "                        show_copy_button=True\n",
        "                    )\n",
        "\n",
        "                with gr.Tab(\"üìä Confidence Report\"):\n",
        "                    confidence_output = gr.Textbox(\n",
        "                        label=\"Analysis Confidence\",\n",
        "                        lines=12,\n",
        "                        max_lines=20,\n",
        "                        show_copy_button=True\n",
        "                    )\n",
        "\n",
        "    # Instructions\n",
        "    gr.Markdown(\"\"\"\n",
        "    ---\n",
        "    ### üìã How to Use\n",
        "    1. **Upload** a dermoscopic or clinical image of the skin lesion\n",
        "    2. **(Optional)** Upload a previous image for evolution tracking\n",
        "    3. **Enable** OpenCV feature extraction for quantitative analysis\n",
        "    4. **Click** \"Analyze Lesion\" and wait 30-60 seconds\n",
        "    5. **Review** results across all tabs\n",
        "\n",
        "    ### ‚ú® Features\n",
        "    - üìê **Calibrated measurements** (size, shape, asymmetry)\n",
        "    - üé® **Color analysis** with clinical terminology\n",
        "    - üî¨ **Dermoscopic structure detection** (pigment network, blue-white veil, etc.)\n",
        "    - ‚ö†Ô∏è **ABCDE risk assessment**\n",
        "    - üìà **Temporal evolution** tracking\n",
        "    - üìö **Evidence-based diagnosis** with literature citations\n",
        "    - üìä **Confidence scoring**\n",
        "    \"\"\")\n",
        "\n",
        "    # Connect button\n",
        "    analyze_btn.click(\n",
        "        fn=analyze_lesion_complete,\n",
        "        inputs=[\n",
        "            image_input, previous_image, previous_date,\n",
        "            use_opencv, manual_data,\n",
        "            max_tokens, temperature, num_sources\n",
        "        ],\n",
        "        outputs=[\n",
        "            opencv_output, dermoscopic_output, sources_output,\n",
        "            diagnosis_output, confidence_output\n",
        "        ]\n",
        "    )\n",
        "# Launch\n",
        "print(\"üöÄ Launching Gradio interface...\")\n",
        "demo.launch(\n",
        "    share=True,\n",
        "    debug=True,\n",
        "    show_error=True\n",
        ")"
      ],
      "metadata": {
        "id": "YsbxYPH-c9-b",
        "outputId": "6ed2d855-6279-4f6a-9a60-9fa038b6733b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 628
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Launching Gradio interface...\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://fc9473ead831c2e4c1.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://fc9473ead831c2e4c1.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}